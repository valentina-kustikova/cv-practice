# Практическая работа №3. Классификация изображений с использованием библиотеки OpenCV

## Реализованные алгоритмы

### 1. Bag of Words (BoW) с SIFT/ORB дескрипторами

**Принцип работы:**

1. **Извлечение локальных признаков**: Для каждого изображения из тренировочной выборки извлекаются локальные
   дескрипторы с помощью алгоритмов SIFT или ORB. Эти дескрипторы описывают характерные ключевые точки изображения (
   углы, края, текстуры).

2. **Построение словаря визуальных слов**: Все извлеченные дескрипторы объединяются и кластеризуются с помощью алгоритма
   MiniBatchKMeans на `n_clusters` кластеров. Каждый центр кластера представляет собой "визуальное слово" в словаре.

3. **Формирование гистограмм**: Для каждого изображения создается гистограмма распределения его дескрипторов по
   визуальным словам. Каждый дескриптор изображения сопоставляется с ближайшим кластерным центром, после чего
   подсчитывается частота попадания в каждый кластер. Полученная гистограмма нормализуется и представляет собой вектор
   признаков изображения.

4. **Классификация**: Обучается линейный классификатор SVM (Support Vector Machine) на полученных векторах признаков.
   SVM строит разделяющую гиперплоскость в пространстве гистограмм для разделения классов.

**Используемые параметры:**

- `n_clusters` (по умолчанию 100) — размер словаря визуальных слов
- `descriptor_type` (SIFT/ORB) — тип используемого дескриптора
- Kernel SVM: linear, C=1.0

**Преимущества:**

- Не требует больших вычислительных ресурсов
- Интерпретируемость признаков
- Работает на CPU

**Недостатки:**

- Зависимость от качества детекции ключевых точек
- Потеря пространственной информации об объектах

---

### 2. Transfer Learning с ResNet-18

**Принцип работы:**

1. **Использование предобученной модели**: Загружается архитектура ResNet-18, предварительно обученная на датасете
   ImageNet. Эта модель уже научилась извлекать универсальные признаки из изображений (от простых (края, текстуры) в
   начальных слоях до сложных (объекты, формы) в глубоких слоях).

2. **Заморозка весов**: Все слои предобученной модели замораживаются (`requires_grad=False`), чтобы сохранить
   извлеченные на ImageNet признаки и избежать переобучения на малом датасете.

3. **Замена классификационного слоя**: Последний полносвязный слой (`fc`) заменяется на новый с количеством выходов,
   равным числу классов в нашей задаче (3 класса достопримечательностей). Обучаются только веса этого нового слоя.

4. **Fine-tuning**: Модель дообучается на тренировочной выборке методом градиентного спуска (Adam optimizer) с функцией
   потерь CrossEntropyLoss.

**Используемые параметры:**

- Базовая модель: ResNet-18
- Optimizer: Adam (lr=0.001)
- Loss: CrossEntropyLoss
- `num_epochs` (по умолчанию 10)
- `batch_size` (по умолчанию 8)

**Преимущества:**

- Высокая точность классификации за счет использования глубоких признаков
- Быстрая сходимость благодаря предобучению
- Автоматическое извлечение признаков

**Недостатки:**

- Требует GPU для эффективного обучения
- Больший размер модели
- Меньшая интерпретируемость

---

## Структура проекта

```
.
├── main.py                     # Точка входа в приложение
├── src/
│   ├── utils.py               # Утилиты для загрузки данных и метрик
│   ├── bag_of_words.py        # Реализация BoW классификатора
│   └── neural_network.py      # Реализация Transfer Learning
├── models/                     # Директория для моделей
├── visualized/                 # Директория для визуализации ключевых точек
├── data/                       # Директория с датасетом
│   ├── ExtDataset/
│   ├── NNSUDataset/
│   └── train.txt
└── README.md
```

---

## Использование

### Параметры командной строки

**Обязательные параметры:**

- `data_dir` — путь к директории с данными
- `train_file` — имя файла с разбиением на train (например, train.txt)
- `mode` — режим работы: `train`, `test` или `full`
- `algorithm` — алгоритм: `bag_of_words` или `neural_network`

**Параметры Bag of Words:**

- `--bow_clusters` — количество кластеров (по умолчанию 100)
- `--bow_descriptor` — тип дескриптора: SIFT или ORB (по умолчанию SIFT)
- `--visualize_bow` — флаг для визуализации ключевых точек

**Параметры нейронной сети:**

- `--nn_epochs` — количество эпох обучения (по умолчанию 10)
- `--nn_batch_size` — размер батча (по умолчанию 8)

---

## Примеры запуска

### Bag of Words

**Полный цикл (обучение + тестирование):**

```bash
python main.py data/ train.txt full bag_of_words --bow_clusters 100 --bow_descriptor SIFT
```

**Только обучение:**

```bash
python main.py data/ train.txt train bag_of_words --bow_clusters 100 --bow_descriptor SIFT
```

**Только тестирование:**

```bash
python main.py data/ train.txt test bag_of_words
```

**С визуализацией ключевых точек:**

```bash
python main.py data/ train.txt full bag_of_words --bow_clusters 100 --visualize_bow
```

### Transfer Learning (ResNet-18)

**Полный цикл (обучение + тестирование):**

```bash
python main.py data/ train.txt full neural_network --nn_epochs 10 --nn_batch_size 8
```

**Только обучение:**

```bash
python main.py data/ train.txt train neural_network --nn_epochs 10 --nn_batch_size 8
```

**Только тестирование:**

```bash
python main.py data/ train.txt test neural_network
```

---

## Результаты экспериментов

### Датасет

Классификация проводилась на изображениях трех достопримечательностей Нижнего Новгорода:

- `01_NizhnyNovgorodKremlin` — Нижегородский Кремль
- `04_ArkhangelskCathedral` — Архангельский собор
- `08_PalaceOfLabor` — Дворец труда

---

### Bag of Words

**Параметры:**

- Количество кластеров: 100
- Дескриптор: SIFT
- Classifier: LinearSVC (C=1.0)

**Метрики:**

```
=== РЕЗУЛЬТАТЫ КЛАССИФИКАЦИИ ===

Точность классификации (Accuracy): 0.9318

Отчет по классификации (Classification Report):
                          precision    recall  f1-score   support

01_NizhnyNovgorodKremlin       0.93      1.00      0.96        39
 04_ArkhangelskCathedral       1.00      0.70      0.82        20
        08_PalaceOfLabor       0.91      1.00      0.95        29

                accuracy                           0.93        88
               macro avg       0.94      0.90      0.91        88
            weighted avg       0.94      0.93      0.93        88
```

**Анализ:**

- Общая точность составила **93.18%**
- Лучше всего классифицируется Архангельский собор (precision 1.00)
- Наименьший recall у Архангельского собора (0.70), что говорит о пропуске 30% изображений этого класса
- Кремль и Дворец труда классифицируются с высоким recall (1.00)

---

### Transfer Learning (ResNet-18)

**Параметры:**

- Базовая модель: ResNet-18 (pretrained на ImageNet)
- Epochs: 10
- Batch size: 8
- Learning rate: 0.001
- Optimizer: Adam

**Метрики:**

```
=== РЕЗУЛЬТАТЫ КЛАССИФИКАЦИИ ===

Точность классификации (Accuracy): 0.9659

Отчет по классификации (Classification Report):
                          precision    recall  f1-score   support

01_NizhnyNovgorodKremlin       0.95      1.00      0.97        39
 04_ArkhangelskCathedral       0.95      0.90      0.92        20
        08_PalaceOfLabor       1.00      0.97      0.98        29

                accuracy                           0.97        88
               macro avg       0.97      0.96      0.96        88
            weighted avg       0.97      0.97      0.97        88
```

**Анализ:**

- Общая точность составила **96.59%** (+3.41% по сравнению с BoW)
- Более сбалансированные результаты по всем классам
- Высокие значения precision и recall для всех трех достопримечательностей
- Дворец труда классифицируется с точностью 100%
- Улучшение recall для Архангельского собора с 0.70 до 0.90

---

## Сравнение методов

| Метрика                   | Bag of Words   | ResNet-18 Transfer Learning |
|---------------------------|----------------|-----------------------------|
| **Accuracy**              | 93.18%         | **96.59%**                  |
| **Macro F1-score**        | 0.91           | **0.96**                    |
| **Weighted F1-score**     | 0.93           | **0.97**                    |
| **Время обучения**        | Быстрее        | Медленнее                   |
| **Требования к ресурсам** | CPU достаточно | Рекомендуется GPU           |

---

## Выводы

1. **Bag of Words** показал хорошие результаты (93.18%) для классического подхода компьютерного зрения, но имеет
   проблемы с классификацией отдельных классов (низкий recall для Архангельского собора).

2. **Transfer Learning на ResNet-18** превзошел BoW на 3.41%, достигнув точности 96.59%. Метод показал более стабильные
   результаты по всем классам благодаря использованию глубоких признаков, извлеченных предобученной сетью.

3. Для практического применения рекомендуется использовать Transfer Learning при наличии GPU, так как он обеспечивает
   более высокую точность и сбалансированность классификации.

4. Bag of Words остается хорошим выбором для задач с ограниченными вычислительными ресурсами или когда требуется быстрое
   прототипирование.

---

## Зависимости

```
opencv-python
numpy
scikit-learn
torch
torchvision
Pillow
joblib
```

Установка:

```bash
pip install opencv-python numpy scikit-learn torch torchvision Pillow joblib
```
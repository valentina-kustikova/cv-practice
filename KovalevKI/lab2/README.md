# Практическая работа №2. Детектирование объектов на изображениях с использованием библиотеки OpenCV

Детектирование объектов на изображениях производится с использованием двух нейросетевых моделей:
- MobileNet-SSD
- YOLOv5s

## 1. `mobilenet_ssd` — MobileNet-SSD (Caffe)

### Предварительная обработка изображения
- Входное изображение масштабируется **без сохранения соотношения сторон** до фиксированного размера `300×300`.
- Нормализация:  
  - `mean=(127.5, 127.5, 127.5)`  
  - `scale=0.007843` (эквивалентно `1/127.5`)
- Цветовое пространство: BGR → RGB (автоматически в `blobFromImage` с `swapRB=True`).

### Обработка выхода сети
- Модель возвращает один тензор формы `(1, 1, N, 7)`, где `N` — число детекций (до 100).
- Каждая детекция: `[batch_id, class_id, confidence, x1, y1, x2, y2]`.
- Координаты `x1, y1, x2, y2` — **нормированы на [0, 1]** относительно исходного изображения.
- Фильтрация:
  - Отбрасываются детекции с `confidence < conf_threshold`.
  - Учитываются только объекты, классифицированные как `car`.
- Координаты преобразуются в пиксели исходного изображения.
- Применяется `cv2.dnn.NMSBoxes` для подавления дубликатов.

### Особенности
- Быстрая модель, но склонна к пропускам мелких/частично закрытых автомобилей.
- Требует отдельного файла конфигурации `.prototxt`.

---

## 2. `yolov5s_onnx` — YOLOv5s

### Предварительная обработка изображения
- Сохранение соотношения сторон с помощью **letterbox-паддинга**:
  - Изображение масштабируется так, чтобы большая сторона стала `640 px`.
  - Добавляется серый паддинг по центру до квадрата `640×640`.
- Нормализация: `/255.0`, `swapRB=True`.
- Выход `preprocess`: `blob`, `scale` (коэффициент масштабирования), `(pad_w, pad_h)` (сдвиг паддинга).

### Обработка выхода сети
- Выход: тензор `(1, 25200, 85)`, где `25200 = 80×80 + 40×40 + 20×20` (ячейки сеток), `85 = 5 + 80` (координаты + классы).
- Для каждой строки:
  - `xc, yc, w, h` — нормированы на 640 (т.е. в диапазоне `[0, 640]`).
  - `conf` — объектность.
  - `class_scores` — 80 значений (COCO).
  - Итоговая уверенность: `confidence = conf * max(class_scores)`.
- Преобразование координат в исходное изображение:
  1. Удаление сдвига от letterbox: `xc -= pad_w`, `yc -= pad_h`.
  2. Демасштабирование: `xc /= scale`, `w /= scale` и т.д.
  3. Перевод из `(xc, yc, w, h)` в `(x1, y1, w, h)`.
- Фильтрация по `confidence > conf_threshold` и `class_id == 2` (`car` в COCO).
- Применяется `cv2.dnn.NMSBoxes`.

### Особенности
- Баланс скорости и точности.
- Корректная обработка паддинга критична: ошибка приводит к смещённым/отрицательным координатам.

## Общие принципы обработки. Реализация интерфейса программы

### `app.py`

Главная исполняемая точка входа приложения, реализующая pipeline оценки детекторов транспорта на видеопоследовательности.

- Поддержка нескольких детекторов (`yolov5s_onnx` или `mobilenet_ssd`) через единый интерфейс `DETECTORS`.
- Сопоставление ground-truth и предсказанных боксов по классу `"car"` (включая обработку класса с `cid == 2`, соответствующего COCO-классу `car` в YOLO).
- Последовательная обработка кадров с выводом TPR/FDR на каждый кадр и средних значений в конце. Гарантируется согласованность порядка `det_boxes`, `det_labels`, `confs` перед вызовом `compute_tpr_fdr`.
- Опциональная визуализация с помощью OpenCV.

### `metrics.py`

Содержит вспомогательные функции для оценки качества обнаружения объектов.

- **Основные функции**:
  - `box_iou(b1, b2)`: вычисляет Intersection over Union (IoU) для двух bounding boxes в формате `(x, y, w, h)`.
  - `compute_tpr_fdr(...)`: рассчитывает:
    - **TPR (True Positive Rate)** = TP / (TP + FN)
    - **FDR (False Discovery Rate)** = FP / (TP + FP) — доля ложных срабатываний среди всех детекций.

  - Детекции сортируются по убыванию уверенности (`confs`).
  - Используется **жадное сопоставление один-к-одному** между детекциями и ground-truth: первая непревзятая GT-метка, имеющая достаточный IoU и совпадающий класс, считается match.
  - Каждая GT-метка может быть сопоставлена **не более чем одной** детекцией.

### Визуализация
- Корректные детекции автомобилей отображаются зелёным.
- Остальные классы — синим.
- Подписи: имя класса и confidence (до 3 знаков).

## Результаты экспериментов

|  | TPR | FDR | Время, с |
|---|---|---|---|
| MobileNet-SSD | 0.451 | 0.027 | 102.89 |
| YOLOv5s | 0.953 | 0.206 | 1531.33 |

Отметим, что время выполнения программы с детектором MobileNet-SSD почти в 15 раз меньше, чем с YOLOv5s. На фото с детектированными объектами видно, что MobileNet-SSD ошибается в классах, не очень точно формирует рамку (на двух схожих фото рамка на одном и том же объекте расположена по-разному), иногда детектирует всё фото как объект какого-либо класса. YOLOv5s же может ошибиться только в случае, когда на фото множеста объектов или они присутствуют на фото лишь частично. Даже в этих случаях рамка отрисовывается достаточно точно, и с большой вероятностью автомобиль будет правильно детектирован по одному только своему элементу.
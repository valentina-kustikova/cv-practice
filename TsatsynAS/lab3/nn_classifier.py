import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import cv2
import numpy as np
import pickle


class NNClassifier:
    def __init__(self, input_shape=(224, 224, 3), num_classes=3):
        self.input_shape = input_shape
        self.num_classes = num_classes
        self.model = None
        self.class_indices = None
        self.is_trained = False

    def _create_model(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º transfer learning"""
        # –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å MobileNetV2
        base_model = tf.keras.applications.MobileNetV2(
            weights='imagenet',
            include_top=False,
            input_shape=self.input_shape
        )

        # –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –±–∞–∑–æ–≤—ã–µ —Å–ª–æ–∏
        base_model.trainable = False

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–≤–æ–∏ —Å–ª–æ–∏
        model = keras.Sequential([
            base_model,
            layers.GlobalAveragePooling2D(),
            layers.Dropout(0.3),
            layers.Dense(128, activation='relu'),
            layers.BatchNormalization(),
            layers.Dropout(0.3),
            layers.Dense(self.num_classes, activation='softmax')
        ])

        model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=0.001),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )

        return model

    def _preprocess_with_opencv(self, images):
        """–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º OpenCV"""
        processed_images = []

        for img in images:
            # –û—Å–Ω–æ–≤–Ω–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ OpenCV
            img_resized = cv2.resize(img, (self.input_shape[0], self.input_shape[1]))

            # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è BGR to RGB (OpenCV –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∫–∞–∫ BGR)
            img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)

            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏
            img_normalized = img_rgb.astype('float32') / 255.0

            processed_images.append(img_normalized)

        return np.array(processed_images)

    def _augment_with_opencv(self, image):
        """–ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º OpenCV (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)"""
        augmented = []

        # –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        augmented.append(image)

        # 1. –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ (OpenCV)
        flipped = cv2.flip(image, 1)
        augmented.append(flipped)

        # 2. –ù–µ–±–æ–ª—å—à–æ–µ —Ä–∞–∑–º—ã—Ç–∏–µ (OpenCV)
        blurred = cv2.GaussianBlur(image, (3, 3), 0)
        augmented.append(blurred)

        return augmented

    def train(self, images, labels, model_path='nn_model.h5', epochs=30, use_augmentation=True):
        if len(images) == 0:
            raise ValueError("–ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")

        print("üîß –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ OpenCV –¥–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")

        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫
        unique_labels = list(set(labels))
        self.class_indices = {label: idx for idx, label in enumerate(unique_labels)}
        self.num_classes = len(unique_labels)

        print(f"–ö–ª–∞—Å—Å—ã: {self.class_indices}")

        # –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Å OpenCV (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        if use_augmentation and len(images) < 200:  # –ê—É–≥–º–µ–Ω—Ç–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö
            augmented_images = []
            augmented_labels = []
            for img, label in zip(images, labels):
                aug_imgs = self._augment_with_opencv(img)
                augmented_images.extend(aug_imgs)
                augmented_labels.extend([label] * len(aug_imgs))

            images = images + augmented_images
            labels = labels + augmented_labels
            print(f"–ü–æ—Å–ª–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ OpenCV: {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")

        y_numeric = np.array([self.class_indices[label] for label in labels])

        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å OpenCV
        X_processed = self._preprocess_with_opencv(images)

        print(f"–§–æ—Ä–º–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ OpenCV –æ–±—Ä–∞–±–æ—Ç–∫–∏: {X_processed.shape}")

        # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        self.model = self._create_model()

        print("üéØ –û–±—É—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏...")

        # Data augmentation –≤ TensorFlow
        datagen = tf.keras.preprocessing.image.ImageDataGenerator(
            rotation_range=20,
            width_shift_range=0.2,
            height_shift_range=0.2,
            horizontal_flip=True,
            validation_split=0.2
        )

        history = self.model.fit(
            datagen.flow(X_processed, y_numeric, batch_size=16, subset='training'),
            epochs=epochs,
            validation_data=datagen.flow(X_processed, y_numeric, batch_size=16, subset='validation'),
            verbose=1
        )

        # Fine-tuning
        print("üîß Fine-tuning...")
        self.model.layers[0].trainable = True
        self.model.compile(
            optimizer=keras.optimizers.Adam(learning_rate=0.0001),
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )

        history_fine = self.model.fit(
            datagen.flow(X_processed, y_numeric, batch_size=16, subset='training'),
            epochs=10,
            validation_data=datagen.flow(X_processed, y_numeric, batch_size=16, subset='validation'),
            verbose=1
        )

        self.is_trained = True
        self.save(model_path)
        print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {model_path}")

        return history

    def predict(self, images):
        if not self.is_trained:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")

        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å OpenCV
        X_processed = self._preprocess_with_opencv(images)

        predictions = self.model.predict(X_processed, verbose=0)
        predicted_indices = np.argmax(predictions, axis=1)

        # –û–±—Ä–∞—Ç–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –≤ –º–µ—Ç–∫–∏
        index_to_class = {v: k for k, v in self.class_indices.items()}
        return [index_to_class[idx] for idx in predicted_indices]

    def demonstrate_opencv_usage(self, image):
        """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è OpenCV"""
        print("üéØ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è OpenCV –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–µ:")
        print(f"   - –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image.shape}")

        # –ü–æ–∫–∞–∂–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ OpenCV
        resized = cv2.resize(image, (224, 224))
        print(f"   - –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞: {resized.shape}")

        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        print(f"   - –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ grayscale: {gray.shape}")

        blurred = cv2.GaussianBlur(image, (5, 5), 0)
        print(f"   - –†–∞–∑–º—ã—Ç–∏–µ –ì–∞—É—Å—Å–∞: {blurred.shape}")

        print("‚úÖ OpenCV –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π!")

    def save(self, path):
        self.model.save(path)
        with open(path.replace('.h5', '_classes.pkl'), 'wb') as f:
            pickle.dump(self.class_indices, f)

    def load(self, path):
        self.model = keras.models.load_model(path)
        with open(path.replace('.h5', '_classes.pkl'), 'rb') as f:
            self.class_indices = pickle.load(f)
        self.is_trained = True
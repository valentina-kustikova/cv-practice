import os
import cv2
import numpy as np
from sklearn.metrics import classification_report, accuracy_score


def load_images_from_paths(file_paths, base_path, labels):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ –ø—É—Ç—è–º –∏–∑ —Ñ–∞–π–ª–∞ —Ä–∞–∑–±–∏–µ–Ω–∏—è"""
    images = []
    image_labels = []
    failed_loads = []

    for file_path, label in zip(file_paths, labels):
        full_path = os.path.join(base_path, file_path)
        try:
            img = cv2.imread(full_path)
            if img is not None:
                images.append(img)
                image_labels.append(label)
            else:
                print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {full_path}")
                failed_loads.append(full_path)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {full_path}: {e}")
            failed_loads.append(full_path)

    if failed_loads:
        print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {len(failed_loads)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")

    return images, image_labels


def parse_split_file(split_file_path):
    """–ü–∞—Ä—Å–∏–Ω–≥ —Ñ–∞–π–ª–∞ —Ä–∞–∑–±–∏–µ–Ω–∏—è –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–æ–∫ –∏–∑ –ø—É—Ç–µ–π"""
    with open(split_file_path, 'r', encoding='utf-8') as f:
        lines = [line.strip() for line in f if line.strip()]

    file_paths = []
    labels = []

    for line in lines:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∫—É –∏–∑ –ø—É—Ç–∏
        if '01_NizhnyNovgorodKremlin' in line:
            label = 'kremlin'
        elif '04_ArkhangelskCathedral' in line:
            label = 'sobor'
        elif '08_PalaceOfLabor' in line:
            label = 'palace'
        else:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∫–ª–∞—Å—Å—ã
            print(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–ª–∞—Å—Å –≤ –ø—É—Ç–∏: {line}")
            continue

        file_paths.append(line)
        labels.append(label)

    print(f"–ù–∞–π–¥–µ–Ω–æ {len(file_paths)} –≤–∞–ª–∏–¥–Ω—ã—Ö –ø—É—Ç–µ–π –≤ —Ñ–∞–π–ª–µ {os.path.basename(split_file_path)}")
    return file_paths, labels


def find_all_images(data_path):
    """–ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ"""
    image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')
    all_images = []

    for root, dirs, files in os.walk(data_path):
        for file in files:
            if file.lower().endswith(image_extensions):
                full_path = os.path.join(root, file)
                # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –æ—Ç data_path
                rel_path = os.path.relpath(full_path, data_path)
                all_images.append(rel_path)

    return all_images


def load_dataset(data_path, split_file_path):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–∞–π–ª–∞ —Ä–∞–∑–±–∏–µ–Ω–∏—è"""

    print("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ä–∞–∑–±–∏–µ–Ω–∏–µ–º –Ω–∞ train/test...")

    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ train.txt
    if os.path.exists(split_file_path):
        train_paths, train_labels = parse_split_file(split_file_path)
        train_images, train_labels = load_images_from_paths(train_paths, data_path, train_labels)
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(train_images)}")
    else:
        print(f"‚ùå Train file not found: {split_file_path}")
        return [], [], [], []

    # –ù–∞—Ö–æ–¥–∏–º –í–°–ï –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ
    all_images = find_all_images(data_path)
    print(f"üìä –í—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ: {len(all_images)}")

    # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ)
    train_relative_paths = [os.path.relpath(os.path.join(data_path, path), data_path)
                            for path in train_paths]

    # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ = –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –º–∏–Ω—É—Å —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ
    test_paths = []
    test_labels = []

    for img_path in all_images:
        if img_path not in train_relative_paths:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –º–µ—Ç–∫—É –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if '01_NizhnyNovgorodKremlin' in img_path:
                label = 'kremlin'
            elif '04_ArkhangelskCathedral' in img_path:
                label = 'sobor'
            elif '08_PalaceOfLabor' in img_path:
                label = 'palace'
            else:
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∫–ª–∞—Å—Å—ã

            test_paths.append(img_path)
            test_labels.append(label)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    test_images, test_labels = load_images_from_paths(test_paths, data_path, test_labels)
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(test_images)}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–µ—Ç –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π
    train_set = set(train_relative_paths)
    test_set = set(test_paths)
    intersection = train_set.intersection(test_set)

    if intersection:
        print(f"‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –Ω–∞–π–¥–µ–Ω–æ {len(intersection)} –ø–µ—Ä–µ—Å–µ–∫–∞—é—â–∏—Ö—Å—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π!")
    else:
        print("‚úÖ Train –∏ test –Ω–∞–±–æ—Ä—ã –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è")

    return train_images, train_labels, test_images, test_labels


def evaluate_classifier(true_labels, predicted_labels):
    accuracy = accuracy_score(true_labels, predicted_labels)
    report = classification_report(true_labels, predicted_labels)
    return accuracy, report


def visualize_keypoints(image, detector_name='SIFT'):
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image

    if detector_name == 'SIFT':
        detector = cv2.SIFT_create()
    elif detector_name == 'ORB':
        detector = cv2.ORB_create()
    else:
        detector = cv2.SIFT_create()

    keypoints = detector.detect(gray, None)
    img_with_kp = cv2.drawKeypoints(image, keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)

    return img_with_kp, len(keypoints)


def get_class_distribution(labels):
    """–ü–æ–ª—É—á–∏—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤"""
    unique, counts = np.unique(labels, return_counts=True)
    return dict(zip(unique, counts))


def resize_images(images, target_size=(224, 224)):
    """–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–æ —Ü–µ–ª–µ–≤–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞"""
    resized_images = []
    for img in images:
        resized_img = cv2.resize(img, target_size)
        resized_images.append(resized_img)
    return resized_images
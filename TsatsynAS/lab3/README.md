# Практическая работа №3. Классификация изображений с использованием библиотеки OpenCV

## Описание проекта

Данная работа представляет собой приложение для классификации изображений трех известных достопримечательностей Нижнего Новгорода:
- **Нижегородский Кремль** (01_NizhnyNovgorodKremlin)
- **Архангельский собор** (04_ArkhangelskCathedral)
- **Дворец труда** (08_PalaceOfLabor)

Приложение реализует два алгоритма классификации:
1. **Алгоритм "Мешок слов" (Bag of Words, BOW)** с использованием различных детекторов и дескрипторов OpenCV
2. **Нейросетевой классификатор** на основе transfer learning с использованием предобученной модели MobileNetV2

## Структура проекта

```
.
├── main.py                 # Главный скрипт приложения
├── bow_classifier.py       # Реализация алгоритма "мешок слов"
├── nn_classifier.py        # Реализация нейросетевого классификатора
├── utils.py                # Утилиты для загрузки и обработки данных
├── demo.py                 # Демонстрация работы OpenCV детекторов
├── check.py                # Скрипт для проверки разбиения данных
├── README.md               # Данный файл
└── nngu/                   # Директория с данными
    └── NNClassification/
        ├── NNSUDataset/    # Фотографии студентов ИИТММ
        ├── ExtDataset/      # Фотографии из сети Интернет
        ├── train.txt        # Файл разбиения на тренировочную выборку
        └── test.txt         # Файл разбиения на тестовую выборку
```

### Зависимости

Для работы приложения необходимо установить следующие библиотеки:

```bash
pip install opencv-python
pip install numpy
pip install scikit-learn
pip install tensorflow
pip install matplotlib
```

## Использование

### Основной скрипт

Главный скрипт `main.py` принимает следующие параметры командной строки:

```bash
python main.py --data_path <путь_к_данным> --split_file <файл_разбиения> --mode <режим> --algorithm <алгоритм> [опции]
```

#### Обязательные параметры:

- `--data_path` - Путь к корневой директории с данными (содержит NNSUDataset и ExtDataset)
- `--split_file` - Путь к файлу разбиения на train/test (например, train.txt)
- `--mode` - Режим работы: `train`, `test` или `both`
- `--algorithm` - Алгоритм классификации: `bow` (мешок слов) или `nn` (нейронная сеть)

#### Параметры для алгоритма BOW:

- `--vocab_size` - Размер словаря для BOW (по умолчанию: 100)
- `--detector` - Детектор ключевых точек: `SIFT`, `ORB` или `AKAZE` (по умолчанию: SIFT)
- `--model_path` - Путь для сохранения/загрузки модели (по умолчанию: bow_model.pkl)

#### Параметры для нейронной сети:

- `--epochs` - Количество эпох обучения (по умолчанию: 50)
- `--batch_size` - Размер батча (по умолчанию: 32)
- `--model_path` - Путь для сохранения/загрузки модели (по умолчанию: nn_model.h5)

### Примеры использования

#### Обучение модели BOW с детектором SIFT:

```bash
python main.py --data_path nngu/NNClassification --split_file nngu/train.txt --mode train --algorithm bow --detector SIFT --vocab_size 200
```

#### Тестирование обученной модели BOW:

```bash
python main.py --data_path nngu/NNClassification --split_file nngu/train.txt --mode test --algorithm bow --model_path bow_model.pkl
```

#### Обучение и тестирование нейронной сети:

```bash
python main.py --data_path nngu/NNClassification --split_file nngu/train.txt --mode both --algorithm nn --epochs 30
```

#### Обучение модели BOW с детектором ORB:

```bash
python main.py --data_path nngu/NNClassification --split_file nngu/train.txt --mode train --algorithm bow --detector ORB --vocab_size 150
```

## Описание реализованных алгоритмов

### 1. Алгоритм "Мешок слов" (Bag of Words)

#### Принцип работы:

1. **Извлечение ключевых точек и дескрипторов**: Используются детекторы OpenCV (SIFT, ORB, AKAZE) для обнаружения ключевых точек и вычисления их дескрипторов на всех изображениях тренировочной выборки.

2. **Построение словаря**: Все дескрипторы собираются вместе и кластеризуются методом K-means (реализовано через `cv2.BOWKMeansTrainer`). Центры кластеров образуют визуальный словарь заданного размера.

3. **Извлечение признаков**: Для каждого изображения вычисляется гистограмма частоты встречаемости "слов" из словаря. Это делается с помощью `cv2.BOWImgDescriptorExtractor`, который сопоставляет дескрипторы ключевых точек изображения с ближайшими центрами кластеров словаря.

4. **Классификация**: На основе полученных гистограмм обучается классификатор Random Forest из библиотеки scikit-learn.

#### Особенности реализации:

- **Поддержка различных детекторов**: SIFT (Scale-Invariant Feature Transform), ORB (Oriented FAST and Rotated BRIEF), AKAZE (Accelerated-KAZE)
- **Нормализация признаков**: Использование StandardScaler для улучшения качества классификации
- **Визуализация**: Возможность визуализации ключевых точек на изображениях (см. `demo.py`)

#### Преимущества:

- Не требует больших вычислительных ресурсов
- Хорошо работает с небольшими наборами данных
- Позволяет исследовать различные детекторы и дескрипторы

### 2. Нейросетевой классификатор

#### Принцип работы:

1. **Transfer Learning**: Используется предобученная модель MobileNetV2, обученная на ImageNet. Базовые слои замораживаются, добавляются собственные слои для классификации.

2. **Предобработка изображений**: 
   - Изменение размера до 224x224 пикселей (с использованием OpenCV)
   - Конвертация из BGR в RGB
   - Нормализация значений пикселей в диапазон [0, 1]

3. **Аугментация данных**: 
   - Горизонтальное отражение (flip)
   - Размытие Гаусса
   - Использование ImageDataGenerator из TensorFlow для дополнительной аугментации (повороты, сдвиги)

4. **Обучение**: 
   - Первый этап: обучение только новых слоев (базовая модель заморожена)
   - Второй этап (fine-tuning): размораживание базовой модели и дообучение с меньшим learning rate

#### Архитектура модели:

```
MobileNetV2 (базовая модель, заморожена)
    ↓
GlobalAveragePooling2D
    ↓
Dropout(0.3)
    ↓
Dense(128, activation='relu')
    ↓
BatchNormalization
    ↓
Dropout(0.3)
    ↓
Dense(3, activation='softmax')  # 3 класса
```

#### Преимущества:

- Высокая точность классификации благодаря transfer learning
- Эффективное использование предобученных весов
- Хорошая обобщающая способность даже на небольших наборах данных

## Результаты работы

Приложение выводит следующие метрики качества классификации:

- **Точность (Accuracy)** - общая точность классификации на тестовой выборке
- **Classification Report** - детальный отчет с метриками precision, recall, F1-score для каждого класса

Пример вывода:

```
Точность: 0.8750
Отчет классификации:
              precision    recall  f1-score   support

      kremlin       0.90      0.85      0.87        20
       palace       0.88      0.90      0.89        20
        sobor       0.85      0.88      0.86        19

    accuracy                           0.88        59
   macro avg       0.88      0.88      0.88        59
weighted avg       0.88      0.88      0.88        59
```



## Технические детали реализации

### Модульная архитектура

Проект реализован с использованием объектно-ориентированного подхода:

- **BOWClassifier** - класс для реализации алгоритма "мешок слов"
- **NNClassifier** - класс для реализации нейросетевого классификатора
- Функции в `utils.py` - утилиты для загрузки и обработки данных

### Использование OpenCV

OpenCV используется для:

1. **Загрузки изображений**: `cv2.imread()`
2. **Изменения размера**: `cv2.resize()`
3. **Конвертации цветовых пространств**: `cv2.cvtColor()`
4. **Детекции ключевых точек**: SIFT, ORB, AKAZE детекторы
5. **Построения BOW словаря**: `cv2.BOWKMeansTrainer`, `cv2.BOWImgDescriptorExtractor`
6. **Аугментации данных**: `cv2.flip()`, `cv2.GaussianBlur()`

### Обработка данных

- Автоматическое определение меток классов из структуры директорий
- Корректное разбиение на train/test на основе файла разбиения
- Проверка отсутствия пересечений между тренировочной и тестовой выборками
- Обработка ошибок загрузки изображений

## Рекомендации по использованию

1. **Для небольших наборов данных** рекомендуется использовать алгоритм BOW с детектором SIFT
2. **Для достижения максимальной точности** рекомендуется использовать нейросетевой классификатор
3. **Для исследования различных детекторов** можно запустить `demo.py` для визуализации ключевых точек
4. **Перед обучением** рекомендуется проверить разбиение данных с помощью `check.py`



import cv2
import numpy as np
import pickle
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler


class BOWClassifier:
    def __init__(self, vocab_size=100, detector='SIFT'):
        self.vocab_size = vocab_size
        self.detector_name = detector
        self.detector = self._create_detector()
        self.bow_extractor = None
        self.classifier = None
        self.scaler = StandardScaler()
        self.is_trained = False
        self.vocabulary = None

    def _create_detector(self):
        try:
            if self.detector_name == 'SIFT':
                return cv2.SIFT_create()
            elif self.detector_name == 'ORB':
                return cv2.ORB_create(nfeatures=1000)
            elif self.detector_name == 'AKAZE':
                return cv2.AKAZE_create()
            else:
                return cv2.SIFT_create()
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ {self.detector_name}: {e}")
            return cv2.SIFT_create()

    def _create_bow_extractor(self, descriptors_list):
        """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–∞—Å—Ç–æ—è—â–µ–≥–æ BOW —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞ OpenCV"""
        print("üéØ –°–æ–∑–¥–∞–Ω–∏–µ BOW —Å–ª–æ–≤–∞—Ä—è —Å OpenCV...")

        # –°–æ–∑–¥–∞–µ–º BOW trainer
        bow_trainer = cv2.BOWKMeansTrainer(self.vocab_size)

        # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä—ã –≤ trainer
        total_descriptors = 0
        for descriptors in descriptors_list:
            if descriptors is not None:
                bow_trainer.add(descriptors.astype(np.float32))
                total_descriptors += len(descriptors)

        print(f"üìä –í—Å–µ–≥–æ –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–æ–≤ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {total_descriptors}")

        # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é OpenCV
        print("üîç –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–æ–≤ OpenCV...")
        self.vocabulary = bow_trainer.cluster()
        print(f"‚úÖ –°–ª–æ–≤–∞—Ä—å —Å–æ–∑–¥–∞–Ω: {self.vocabulary.shape}")

        # –°–æ–∑–¥–∞–µ–º BOW —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä
        self.bow_extractor = cv2.BOWImgDescriptorExtractor(
            self.detector,
            cv2.BFMatcher(cv2.NORM_L2)
        )
        self.bow_extractor.setVocabulary(self.vocabulary)

        return self.bow_extractor

    def train(self, images, labels, model_path='bow_model.pkl'):
        if len(images) == 0:
            raise ValueError("–ù–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")

        print(f"üéØ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è BOW –Ω–∞ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö...")
        print(f"üîß –î–µ—Ç–µ–∫—Ç–æ—Ä: {self.detector_name}, –°–ª–æ–≤–∞—Ä—å: {self.vocab_size}")

        # 1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–æ–≤ OpenCV
        print("1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä–æ–≤ OpenCV...")
        descriptors_list = []
        for i, img in enumerate(images):
            if len(img.shape) == 3:
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            else:
                gray = img

            keypoints, descriptors = self.detector.detectAndCompute(gray, None)
            descriptors_list.append(descriptors)

            if (i + 1) % 20 == 0:
                kp_count = len(keypoints) if keypoints else 0
                print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i + 1}/{len(images)} (—Ç–æ—á–µ–∫: {kp_count})")

        # 2. –°–æ–∑–¥–∞–Ω–∏–µ BOW —Å–ª–æ–≤–∞—Ä—è OpenCV
        print("2. –°–æ–∑–¥–∞–Ω–∏–µ BOW —Å–ª–æ–≤–∞—Ä—è OpenCV...")
        self._create_bow_extractor(descriptors_list)

        # 3. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ BOW –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å OpenCV
        print("3. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ BOW –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ OpenCV...")
        bow_features = []
        valid_indices = []

        for i, img in enumerate(images):
            if len(img.shape) == 3:
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            else:
                gray = img

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç–æ—è—â–∏–π BOW —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä OpenCV
            keypoints = self.detector.detect(gray, None)
            if len(keypoints) > 0:
                bow_descriptor = self.bow_extractor.compute(gray, keypoints)
                if bow_descriptor is not None:
                    bow_features.append(bow_descriptor.flatten())
                    valid_indices.append(i)
                else:
                    bow_features.append(np.zeros(self.vocab_size))
            else:
                bow_features.append(np.zeros(self.vocab_size))

            if (i + 1) % 20 == 0:
                print(f"   –ò–∑–≤–ª–µ—á–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è {i + 1}/{len(images)}")

        bow_features = np.array(bow_features)
        filtered_labels = [labels[i] for i in range(len(images))]

        print(f"üìä –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å BOW –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {bow_features.shape}")

        # 4. –û–±—É—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
        print("4. –û–±—É—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞...")
        bow_features = self.scaler.fit_transform(bow_features)

        self.classifier = RandomForestClassifier(
            n_estimators=100,
            random_state=42,
            max_depth=10
        )
        self.classifier.fit(bow_features, filtered_labels)

        self.is_trained = True
        self.save(model_path)
        print(f"üíæ BOW –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {model_path}")

    def predict(self, images):
        if not self.is_trained:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")

        print("üîç –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ BOW –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è...")
        features = []

        for img in images:
            if len(img.shape) == 3:
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            else:
                gray = img

            keypoints = self.detector.detect(gray, None)
            if len(keypoints) > 0:
                bow_descriptor = self.bow_extractor.compute(gray, keypoints)
                if bow_descriptor is not None:
                    features.append(bow_descriptor.flatten())
                else:
                    features.append(np.zeros(self.vocab_size))
            else:
                features.append(np.zeros(self.vocab_size))

        features = self.scaler.transform(np.array(features))
        return self.classifier.predict(features)

    def save(self, path):
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–µ –æ–±—ä–µ–∫—Ç—ã
        with open(path, 'wb') as f:
            pickle.dump({
                'vocab_size': self.vocab_size,
                'detector_name': self.detector_name,
                'vocabulary': self.vocabulary,
                'classifier': self.classifier,
                'scaler': self.scaler,
                'is_trained': self.is_trained
            }, f)

    def load(self, path):
        with open(path, 'rb') as f:
            data = pickle.load(f)

        self.vocab_size = data['vocab_size']
        self.detector_name = data['detector_name']
        self.detector = self._create_detector()
        self.vocabulary = data['vocabulary']

        # –í–æ—Å—Å–æ–∑–¥–∞–µ–º BOW —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ
        self.bow_extractor = cv2.BOWImgDescriptorExtractor(
            self.detector,
            cv2.BFMatcher(cv2.NORM_L2)
        )
        self.bow_extractor.setVocabulary(self.vocabulary)

        self.classifier = data['classifier']
        self.scaler = data['scaler']
        self.is_trained = data['is_trained']
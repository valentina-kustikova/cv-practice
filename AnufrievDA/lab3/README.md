# Практическая работа №3. Классификация изображений с использованием библиотеки OpenCV

**Выполнил:** Ануфриев Даниил  
**Группа:** 3822Б1ПМОП3

В рамках работы разработано приложение для классификации изображений достопримечательностей Нижнего Новгорода:
1.  Нижегородский Кремль (NizhnyNovgorodKremlin)
2.  Архангельский собор (ArkhangelskCathedral)
3.  Дворец труда (PalaceOfLabor)

Реализовано два подхода:
*   **Классический Computer Vision:** Алгоритм «Мешок визуальных слов» (Bag of Visual Words, BoVW).
*   **Глубокое обучение:** Сверточные нейросети (CNN) с использованием Transfer Learning.

---

## Описание реализации

### Структура проекта
*   `models/bovw_model.py` — Класс `BoVWClassifier`. Реализует конвейер: детектор (SIFT/ORB) -> кластеризация (MiniBatchKMeans) -> классификатор (SVM).
*   `models/cnn_model.py` — Класс `CNNClassifier`. Реализует загрузку предобученных моделей (ResNet18, MobileNetV2) и дообучение последнего полносвязного слоя на PyTorch.
*   `utils/dataset_loader.py` — Утилиты для загрузки изображений и автоматического определения меток классов по именам файлов (`01_`, `04_`, `08_`).
*   `train.py` — Точка входа. Принимает аргументы командной строки для выбора алгоритма и параметров обучения.

### Используемые алгоритмы

#### 1. Bag of Visual Words (BoVW)
Метод основан на поиске ключевых точек на изображении.
*   **Детекторы:** Исследованы SIFT (Scale-Invariant Feature Transform) и ORB (Oriented FAST and Rotated BRIEF).
*   **Словарь:** Дескрипторы кластеризуются алгоритмом K-Means (использован MiniBatchKMeans для ускорения) для формирования "визуального словаря".
*   **Классификация:** Гистограммы частот визуальных слов подаются на вход SVM (Support Vector Machine) с RBF-ядром.

#### 2. Convolutional Neural Network (CNN)
Использован метод Transfer Learning (перенос обучения).
*   **Модели:** ResNet18 и MobileNetV2, предобученные на датасете ImageNet.
*   **Обучение:** Веса сверточных слоев используются для извлечения признаков, дообучается только финальный классификатор под 3 целевых класса.

---

## Результаты экспериментов

**Данные:**
*   Тренировочная выборка: 131 изображение.
*   Тестовая выборка: 88 изображений.

### 1. CNN: ResNet18
*   Параметры: `epochs=10`, `batch_size=16`, `lr=1e-4`
*   **Accuracy: 1.0000 (100%)**

**Confusion Matrix:**
```
[[39  0  0]
 [ 0 20  0]
 [ 0  0 29]]
```

### 2. CNN: MobileNetV2
*   Параметры: `epochs=10`, `batch_size=16`, `lr=1e-4`
*   **Accuracy: 1.0000 (100%)**

**Confusion Matrix:**
```
[[39  0  0]
 [ 0 20  0]
 [ 0  0 29]]
```

### 3. BoVW + SIFT
*   Параметры: `clusters=100`, `nfeatures=500`
*   **Accuracy: 0.8977 (~90%)**

**Confusion Matrix:**
```
[[39  0  0]
 [ 3 16  1]
 [ 2  3 24]]
```

### 4. BoVW + ORB
*   Параметры: `clusters=100`, `nfeatures=500`
*   **Accuracy: 0.8409 (~84%)**

**Confusion Matrix:**
```
[[36  3  0]
 [ 4 14  2]
 [ 4  1 24]]
```

---

## Итоговое сравнение

| Метод | BoVW + ORB | BoVW + SIFT | CNN: MobileNetV2 | CNN: ResNet18 |
| :--- | :--- | :--- | :--- | :--- |
| **Параметры** | clusters=100 | clusters=100 | epochs=10 | epochs=10 |
| **Accuracy** | 0.8409 | 0.8977 | **1.0000** | **1.0000** |

### Вывод
1.  **Нейросетевой подход (CNN)** показал наилучший результат (**100% точность**). Обе модели (ResNet18 и MobileNetV2) безошибочно классифицировали тестовую выборку. Это объясняется тем, что предобученные сверточные сети извлекают более глубокие и устойчивые семантические признаки, чем классические дескрипторы.
2.  **Классический подход (BoVW)** показал достойный результат (84-90%), но уступил нейросетям.
3.  **Сравнение детекторов:** Детектор **SIFT (89.7%)** оказался точнее, чем **ORB (84.1%)**. Это ожидаемо, так как SIFT более устойчив к изменениям масштаба и поворота, хотя и требует больше вычислительных ресурсов. ORB работает быстрее, но дает менее качественные признаки для данной задачи.
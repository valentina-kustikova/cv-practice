# Практическая работа №2. Детектирование объектов на изображениях с использованием библиотеки OpenCV

## Алгоритмы детектирования транспортных средств

### Алгоритм YOLOv4

**Процесс детектирования:**

1. **Предобработка изображения**
   - Изменение размера до 416x416 пикселей
   - Нормализация значений пикселей: $x = \frac{x}{255.0}$
   - Конвертация изображения в 4-мерный тензор (blob)

2. **Прямое распространение через сеть**
   - Извлечение признаков через CSPDarknet53
   - Предсказание bounding boxes и классов на разных масштабах

3. **Постобработка**
   - Для каждой детекции вычисляется общая уверенность:
     $$p_{total} = p_{object} \times \max(p_{class})$$
   - Выбор класса детектированного объекта: $$\hat{c} = \arg\max_k p_k$$
   - Фильтрация детекций по порогу уверенности: $$p_{total} \geq \tau_{conf}$$
   - Преобразование координат из формата (center_x, center_y, width, height) в (x1, y1, x2, y2):
     $$x_1 = x_c - \frac{w}{2}, \quad y_1 = y_c - \frac{h}{2}$$
     $$x_2 = x_1 + w, \quad y_2 = y_1 + h$$
   - Применение Non-Maximum Suppression (NMS) для устранения дублирующих bounding boxes
   - Масштабирование координат обратно к исходному размеру изображения

### Алгоритм SSD MobileNet

**Процесс детектирования:**

1. **Предобработка изображения**
   - Изменение размера до 600x600 пикселей
   - Конвертация изображения в 4-мерный тензор (blob)

2. **Извлечение признаков**
   - Глубинные separable свертки для эффективного извлечения признаков
   - Многоуровневое детектирование на разных feature maps

3. **Постобработка**
   - Фильтрация по порогу уверенности: $p \geq \tau_{conf}$
   - Применение NMS для устранения дубликатов
   - Масштабирование координат из нормализованных [0,1] в абсолютные:
     $$x_{pix} = x \cdot W, \quad y_{pix} = y \cdot H$$
     где W и H - ширина и высота исходного изображения

### Алгоритм Faster R-CNN

**Процесс детектирования:**

1. **Предобработка изображения**
   - Изменение размера до 300x300 пикселей
   - Конвертация изображения в 4-мерный тензор (blob)

2. **Генерация регионов интереса**
   - Region Proposal Network (RPN) генерирует candidate bounding boxes
   - Отбор наиболее перспективных регионов

3. **Постобработка**
   - Фильтрация по порогу уверенности: $$p \geq \tau_{conf}$$
   - Применение NMS для устранения дубликатов
   - Масштабирование координат из нормализованных [0,1] в абсолютные

---

## Методика оценки качества

Для оценки качества работы детекторов применяются показатели **TPR (True Positive Rate)** и **FDR (False Discovery Rate)**. Метрики вычисляются на основе пересечения предсказанных рамок с разметкой (Ground Truth) по критерию **IoU (Intersection over Union)**.

### Intersection over Union (IoU)
$$IoU(A,B) = \frac{|A \cap B|}{|A \cup B|} = \frac{|A \cap B|}{|A| + |B| - |A \cap B|}$$

где:
- $$A \cap B$$ - площадь пересечения predicted и ground truth bounding boxes
- $$A \cup B$$ - площадь объединения bounding boxes

### True Positive Rate (TPR) / Recall
$$TPR = \frac{TP}{TP + FN}$$

Показывает, какая доля реальных объектов была правильно детектирована

### False Detection Rate (FDR)
$$FDR = \frac{FP}{TP + FP}$$

Показывает, какая доля детекций является ложными срабатываниями

### Критерии классификации:
- **True Positive (TP)**: Детекция считается корректной если $IoU \geq 0.5$ и класс правильный
- **False Positive (FP)**: Детекция с $IoU < 0.5$ или неправильным классом
- **False Negative (FN)**: Объект из ground truth не был детектирован

### Non-Maximum Suppression (NMS)
Алгоритм применяется для устранения дублирующих bounding boxes:
- Детекции сортируются по уверенности: $detections \leftarrow sort(detections, confidence)$
- Для каждой пары детекций вычисляется IoU
- Если $IoU(det_i, det_j) > \tau_{nms}$, то менее уверенная детекция удаляется

---

## Программная реализация

### Структура классов:

- **BaseDetector** - базовый класс, содержащий общую логику для всех детекторов
- **YOLODetector** - реализация алгоритма YOLOv4
- **SSDMobileNetDetector** - реализация алгоритма SSD MobileNet
- **FasterRCNNDetector** - реализация алгоритма Faster R-CNN
- **VehicleDetectorFactory** - фабрика для создания детекторов
- **DetectionEvaluator** - класс для оценки качества детектирования
- **AnnotationLoader** - класс для загрузки аннотаций
- **VehicleDetectionApp** - основной класс приложения

### Основные модули:

- `base_struct.py` - базовые классы и структуры данных (Detection, ModelConfig, BaseDetector)
- `detectors.py` - реализации конкретных детекторов (YOLO, SSD MobileNet, Faster R-CNN)
- `factory.py` - фабрика для создания детекторов
- `evaluator.py` - класс для оценки качества детектирования
- `annotation_loader.py` - класс для работы с аннотациями
- `app.py` - основной класс приложения
- `main.py` - основной скрипт для запуска приложения

### Входные параметры приложения:

- `--images` - путь к директории с изображениями (обязательный параметр)
- `--annotations` - путь к файлу с аннотациями (обязательный параметр)
- `--model` - алгоритм детектирования: yolo, mobilenet или rcnn (обязательный параметр)
- `--confidence` - порог уверенности для детекций $\tau_{conf}$ (по умолчанию: 0.5)
- `--no-display` - отключить отображение результатов в реальном времени
- `--show-ground-truth` - отображать ground truth bounding boxes

### Выходные данные:

- Детекции транспортных средств в реальном времени
- Метрики качества: True Positive Rate (TPR) и False Discovery Rate (FDR)
- Визуализация bounding boxes с уверенностью
- Статистика по времени обработки

---

## Методы классов

### BaseDetector

**Основные методы:**
- `preprocess` - предобработка изображения для нейронной сети
- `postprocess` - абстрактный метод для постобработки выходов сети
- `_apply_nms` - применение Non-Maximum Suppression для фильтрации дубликатов
- `detect` - основной метод для детектирования объектов на изображении

### YOLODetector

**Основные методы:**
- `postprocess` - обработка выходов YOLO сети, преобразование координат, фильтрация по уверенности

### SSDMobileNetDetector

**Основные методы:**
- `postprocess` - обработка выходов SSD сети, извлечение bounding boxes и классов

### FasterRCNNDetector

**Основные методы:**
- `postprocess` - обработка выходов Faster R-CNN сети, работа с регионами интереса

### VehicleDetectorFactory

**Основные методы:**
- `get_available_models` - возвращает информацию о доступных моделях
- `create_detector` - создает экземпляр детектора по указанному типу

### DetectionEvaluator

**Основные методы:**
- `calculate_iou` - вычисление Intersection over Union для двух bounding boxes
- `evaluate_frame` - оценка качества детектирования для одного кадра
- `get_metrics` - получение агрегированных метрик качества

### AnnotationLoader

**Основные методы:**
- `_load_annotations` - загрузка аннотаций из файла
- `get_ground_truth` - получение ground truth bounding boxes для конкретного изображения

### VehicleDetectionApp

**Основные методы:**
- `draw_detections` - отрисовка bounding boxes детекций на изображении
- `draw_ground_truth` - отрисовка ground truth bounding boxes
- `display_metrics` - отображение метрик качества на изображении
- `run` - основной метод запуска приложения

---

## Метрики качества реализованных моделей

**SSD Mobilenet**
- TPR = 0.813
- FDR = 0.023

**YOLOv4**
- TPR = 0.787  
- FDR = 0.033

**Faster R-CNN**
- TPR = 0.703
- FDR = 0.066

## Выводы

В ходе выполнения работы:
- Реализована система детекции транспортных средств на изображениях
- Поддержаны три различные архитектуры нейронных сетей
- Реализованы алгоритмы предобработки и постобработки для каждой модели
- Выполнена оценка качества с использованием метрик IoU, TPR, FDR
- Построена модульная, расширяемая архитектура приложения
- Обеспечена корректная визуализация результатов и работа с аннотациями

Модель SSD MobileNet показала наилучший баланс между точностью (TPR) и количеством ложных срабатываний (FDR), что делает её наиболее подходящей для практического применения в задачах детектирования транспортных средств.

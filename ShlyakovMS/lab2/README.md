# Практическая работа №2 — Детектирование объектов с использованием OpenCV

## Что делает программа:
1. Загружает выбранный детектор.
2. Считывает изображения из указанной папки.
3. Для каждого кадра:
   - Выполняет предобработку изображения под требуемый формат модели.
   - Пропускает изображение через сеть.
   - Постобрабатывает выход сети: фильтрует по порогу уверенности, преобразует координаты, отфильтровывает нежелательные классы, применяет алгоритм подавления дублей.
   - Сравнивает полученные детекции с аннотированными объектами по IoU и вычисляет метрики кадра (TPR и FDR) — детекции сортируются по confidence (по убыванию), каждая детекция сопоставляется с наилучшей свободной аннотацией того же класса по IoU; если лучшая IoU ≥ 0.5 — детекция считается TP, иначе — FP; оставшиеся несопоставленные аннотации считаются FN.
   - Рисует детекции и служебную информацию на копии кадра и собирает кадры для итогового видео.
4. По завершении:
   - Сортирует кадры по TPR и сохраняет пять лучших и пять худших кадров в отдельные папки.
   - Собирает итоговое видео из обработанных кадров.
   - Сохраняет краткий текстовый отчёт с усреднёнными метриками (агрегированные метрики берутся из суммарных счётчиков: overall TPR = total_TP / (total_TP + total_FN), overall FDR = total_FP / (total_TP + total_FP)).

## Описание детекторов и что именно выполняется для каждой модели

Общие шаги для всех моделей:
- Преобразование изображения в формат, подходящий для входа нейросети.
- Прямой проход через сеть для получения сырых предсказаний.
- Постобработка: получение уверенности и класса для каждой детекции, перевод нормализованных координат в абсолютные, фильтрация по порогу уверенности, фильтрация по списку целевых классов, применение Non-Maximum Suppression для исключения дублирующих прямоугольников, формирование удобного формата результатов (координаты в виде x,y,w,h, уверенность, имя класса).

Детально для каждой модели:

- YOLOv3
  - Предобработка: изображение масштабируется до размера, требуемого сетью, нормализуется путём деления на 255 и преобразуется в 4‑мерный тензор (blob). Цветовой порядок каналов при необходимости меняется.
  - Прямой проход: тензор подаётся в сеть, извлекаются выходные слои, содержащие множество кандидатов. Каждый кандидат состоит из нормализованных координат центра, размеров bbox, значения уверенности объекта и вектора вероятностей классов.
  - Постобработка: для каждого кандидата выбирается класс с максимальной вероятностью и вычисляется соответствующая уверенность. Координаты преобразуются из нормализованного формата в пиксельные значения изображения. Применяются порог уверенности и фильтрация по целевым классам. Затем выполняется подавление перекрытий (NMS) для удаления дубликатов и формируется окончательный список детекций с полями: позиция (x,y,w,h), уверенность и имя класса.

- YOLOv4-tiny
  - Поведение и шаги идентичны YOLOv3, но используется облегчённая версия архитектуры (меньше слоёв и параметров). Это даёт ускорение инференса при некотором снижении точности. Предобработка и формат выводимых данных совпадают с YOLOv3, постобработка делает те же проверки и преобразования.

- MobileNet-SSD
  - Предобработка: изображение изменяется до размера, ожидаемого MobileNet-SSD, и нормализуется по другой схеме (в коде применяется вычитание среднего значения и масштабирование).
  - Прямой проход: сеть возвращает набор детекций в формате, где для каждой детекции указаны вероятность, идентификатор класса и нормализованные координаты прямоугольника (левый‑верхний и правый‑нижний углы).
  - Постобработка: детекции с уверенность ниже порога отбрасываются; нормализованные координаты преобразуются в абсолютные пиксели и ограничиваются рамками изображения; далее применяется фильтрация по списку целевых классов транспортных средств и NMS для удаления перекрывающихся детекций. Итоговая структура детекции сопоставима с YOLO‑вариантами.

## Метрики и способ оценки
- Для каждого кадра производится сопоставление детекций и эталонной разметки с использованием IoU (перекрытие пересечения и объединения).
- Детекции сортируются по полю confidence по убыванию; каждая детекция сопоставляется с наилучшей свободной аннотацией того же класса по IoU.
- Детекция считается TP, если существует неподвязанная аннотация того же класса с IoU ≥ 0.5. В противном случае детекция считается FP.
- FN — это количество аннотаций, которые остались не сопоставленными с детекциями.
- На уровне кадра вычисляются:
  - TPR — доля найденных объектов от числа объектов в разметке кадра (TP / (TP + FN), если знаменатель > 0, иначе 0).
  - FDR — доля ложных срабатываний среди всех детекций кадра (FP / (TP + FP), если знаменатель > 0, иначе 0).
- По завершении вычисляются агрегированные метрики по сумме счётчиков TP/FP/FN по всем кадрам:
  - overall TPR = total_TP / (total_TP + total_FN)
  - overall FDR = total_FP / (total_TP + total_FP)

## Что сохраняется пользователем
- Папки с результатами: внутри указанного каталога результатов создаются подпапки best и worst, куда сохраняются визуализированные 5 лучших и 5 худших кадров по TPR.
- Итоговое видео, собранное из всех обработанных кадров, с наложенными подписями TPR/FDR/количества детекций.
- Краткий текстовый отчёт со средними метриками и информацией о модели.

## Эксперименты:
 - Модель: yolov3 
     - TPR  = 0.9496  
     - FDR  = 0.1293 
   
- Модель: ssd
    - TPR  = 0.7601 
    - FDR  = 0.0278

- Модель: yolov4tiny 
    - TPR  = 0.8616  
    - FDR  = 0.0739 

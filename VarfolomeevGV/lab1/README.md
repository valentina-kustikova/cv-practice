# Практическая работа №1. Обработка изображений с использованием NumPy

## Краткое описание

Проект реализует библиотеку фильтров на Python с применением базовых операций NumPy над матрицами изображений. Все фильтры ожидают на вход цветные (трёхканальные) изображения и оформлены статическими методами класса `ImageFilter` (файл `image_filters/filters.py`). В реализации присутствует GUI на PyQt5 (`image_filters/gui.py`), демонстрирующий работу фильтров и облегчающий настройку параметров.

## Структура проекта

```
.
├── image_filters/
│   ├── __init__.py      # инициализация пакета
│   ├── filters.py       # базовые фильтры (класс ImageFilter)
│   ├── processors.py    # классы обработки: ColorConverter, OverlayProcessor, FilterProcessor
│   └── gui.py           # PyQt5 интерфейс
├── main.py              # точка входа, запускает GUI
└── README.md            # описание проекта и алгоритмов
```

## Архитектура

Проект разделён на несколько модулей:
- **`filters.py`** — содержит класс `ImageFilter` с базовыми фильтрами обработки изображений
- **`processors.py`** — содержит вспомогательные классы:
  - `ColorConverter` — преобразования цветовых пространств (BGR↔RGB, BGR↔Grayscale)
  - `OverlayProcessor` — операции наложения изображений с учётом альфа-канала
  - `FilterProcessor` — применение фильтров с параметрами из GUI
- **`gui.py`** — графический интерфейс для демонстрации и настройки фильтров

## Установка зависимостей

Проект тестировался с Python 3.10+, NumPy 1.24+, PyQt5 5.15+. OpenCV используется только для чтения/записи изображений (`cv2.imread`, `cv2.imwrite`), все операции обработки выполняются через NumPy.

```bash
pip install -r requirements.txt
```

## Запуск демонстрации

```bash
python main.py
```

## Описание реализованных фильтров

### 1. Интерполяция NN (Nearest Neighbour interpolation)

**Алгоритм:**
- На вход подаётся изображение размером `(old_h, old_w, 3)` и целочисленный коэффициент масштабирования `scale_factor`.
- Вычисляются размеры нового изображения: `new_w = floor(scale_factor * old_w)`, `new_h = floor(scale_factor * old_h)`.
- Создаётся пустой массив `new_img_array` размером `(new_h, new_w, 3)`.
- Для каждого пикселя `(i, j)` нового изображения:
  - Вычисляются координаты в исходном изображении: `x = i / scale_factor`, `y = j / scale_factor`.
  - Используется функция `floor()` для округления вниз: `source_i = floor(x)`, `source_j = floor(y)`.
  - Значение пикселя копируется: `new_img_array[i, j] = image[source_i, source_j]`.

**Математическая формула:**
```
source_x = floor(new_x / scale_factor)
source_y = floor(new_y / scale_factor)
result[new_y, new_x] = image[source_y, source_x]
```


### 2. Билинейная интерполяция

**Алгоритм:**
- Масштабирование выполняется векторным способом с использованием `np.linspace` для создания равномерно распределённых координат.
- Для каждого пикселя нового изображения находятся четыре ближайших пикселя исходного изображения:
  - `top_left = image[y0, x0]`
  - `top_right = image[y0, x1]`
  - `bottom_left = image[y1, x0]`
  - `bottom_right = image[y1, x1]`
- Вычисляются дробные части координат для определения весов:
  ```python
  dx = (x_coords - x0)  # расстояние от левой границы
  dy = (y_coords - y0)  # расстояние от верхней границы
  ```
- Выполняется двумерная линейная интерполяция:
  1. **Горизонтальная интерполяция** (по оси X):
     ```python
     top = top_left * (1.0 - dx) + top_right * dx
     bottom = bottom_left * (1.0 - dx) + bottom_right * dx
     ```
  2. **Вертикальная интерполяция** (по оси Y):
     ```python
     interpolated = top * (1.0 - dy) + bottom * dy
     ```

**Математическая формула:**
```
f(x, y) = f(x0, y0) * (1-dx) * (1-dy) + 
          f(x1, y0) * dx * (1-dy) + 
          f(x0, y1) * (1-dx) * dy + 
          f(x1, y1) * dx * dy
```
где `dx = x - x0`, `dy = y - y0` — дробные части координат.


### 3. Линейное изменение разрешения (Linear Resize)

**Алгоритм:**
- Реализует равномерное растяжение массива пикселей без интерполяции (простое повторение/пропуск пикселей).
- Вычисляются индексы для нового изображения:
  ```python
  y_indices = np.linspace(0, original_height - 1, new_height, dtype=np.float64)
  x_indices = np.linspace(0, original_width - 1, new_width, dtype=np.float64)
  ```
- Индексы округляются до ближайших целых и ограничиваются границами:
  ```python
  y_indices = np.clip(np.round(y_indices).astype(np.intp), 0, original_height - 1)
  x_indices = np.clip(np.round(x_indices).astype(np.intp), 0, original_width - 1)
  ```
- Используется fancy-indexing для выборки пикселей:
  ```python
  resized = image[np.ix_(y_indices, x_indices)]
  ```
- Результат приводится к contiguous массиву для эффективности.

**Математическая формула:**
```
y_index[i] = round(i * (H_old - 1) / (H_new - 1))
x_index[j] = round(j * (W_old - 1) / (W_new - 1))
result[i, j] = image[y_index[i], x_index[j]]
```

### 4. Sepia

**Алгоритм:**
- Применяется матричное преобразование цветов для создания эффекта сепии (старинной фотографии).
- Изображение преобразуется в формат `float32` для точных вычислений.
- Используется стандартная матрица преобразования сепии:
  ```python
  sepia_matrix = np.array([
      [0.272, 0.534, 0.131],  # R
      [0.349, 0.686, 0.168],  # G
      [0.393, 0.769, 0.189]   # B
  ], dtype=np.float32)
  ```
- Выполняется матричное умножение: `transformed = image_bgr @ sepia_matrix.T`
- Результат обрезается до диапазона `[0, 255]` и приводится к типу `uint8`.

**Математическая формула:**
```
[R_new]   [0.272  0.534  0.131]   [R_old]
[G_new] = [0.349  0.686  0.168] × [G_old]
[B_new]   [0.393  0.769  0.189]   [B_old]
```


### 5. Vignette

**Алгоритм:**
- Центр виньетки `(cx, cy)` задаётся пользователем или вычисляется как центр изображения: `cx = width / 2`, `cy = height / 2`.
- Координаты центра ограничиваются границами изображения: `cx ∈ [0, width-1]`, `cy ∈ [0, height-1]`.
- Создаётся сетка координат через `np.indices`:
  ```python
  y, x = np.indices((height, width), dtype=np.float32)
  ```
- Вычисляются расстояния от каждого пикселя до центра:
  ```python
  distances = np.sqrt((x - cx) ** 2 + (y - cy) ** 2)
  ```
- Находится максимальное расстояние до углов изображения для нормализации:
  ```python
  distances_to_corners = [расстояния до 4 углов]
  max_distance = max(distances_to_corners)
  max_radius = radius * max_distance
  ```
- Расстояния нормализуются: `normalized = distances / max_radius`
- Создаётся маска ослабления: `mask = 1.0 - intensity * normalized`
- Маска ограничивается диапазоном `[0, 1]` и применяется к изображению:
  ```python
  result = image.astype(np.float32) * mask
  ```

**Математическая формула:**
```
distance(x, y) = sqrt((x - cx)² + (y - cy)²)
normalized = distance / (radius * max_corner_distance)
mask = 1.0 - intensity * normalized
result = image * mask
```

### 6. Pixelation

**Алгоритм:**
- Пользователь задаёт координаты верхнего левого угла `(x, y)` и размеры области `(width, height)`.
- Координаты валидируются и ограничиваются границами изображения:
  ```python
  x = max(0, min(w - 1, int(x)))
  y = max(0, min(h - 1, int(y)))
  width = max(1, int(width))
  height = max(1, int(height))
  ```
- Вычисляются границы области интереса (ROI): `x_end = x + width`, `y_end = y + height`.
- Извлекается регион интереса: `roi = image[y:y_end, x:x_end]`.
- Регион разбивается на сетку блоков размером `pixel_size × pixel_size`:
  ```python
  down_w = roi_w // pixel_size  # количество блоков по ширине
  down_h = roi_h // pixel_size   # количество блоков по высоте
  block_h = roi_h / down_h      # высота одного блока
  block_w = roi_w / down_w      # ширина одного блока
  ```
- **Этап 1 — Уменьшение (downsampling):**
  - Для каждого блока вычисляется среднее значение всех пикселей:
    ```python
    reduced[i, j] = block.mean(axis=(0, 1))  # среднее по всем каналам
    ```
  - Формируется "уменьшенное" изображение размером `(down_h, down_w, channels)`.
- **Этап 2 — Увеличение (upsampling):**
  - Для каждого пикселя исходного размера определяется соответствующий блок:
    ```python
    src_i = int(i / block_h)  # индекс блока по вертикали
    src_j = int(j / block_w)  # индекс блока по горизонтали
    ```
  - Значение из блока копируется во все пиксели этого блока:
    ```python
    pixelated[i, j] = reduced[src_i, src_j]
    ```
- Обработанный регион вставляется обратно в копию исходного изображения.

**Математическая формула:**
```
Для блока (i, j):
  block = roi[y_start:y_end, x_start:x_end]
  reduced[i, j] = mean(block)

Для пикселя (y, x) в pixelated:
  block_i = floor(y / block_h)
  block_j = floor(x / block_w)
  pixelated[y, x] = reduced[block_i, block_j]
```

### 7. Frame (simple)

**Алгоритм:**
- Создаётся прямоугольная рамка указанной толщины `frame_width` и цвета `(R, G, B)`.
- Толщина валидируется: `frame_width = max(0, int(frame_width))`; значение `0` означает отсутствие рамки.
- Толщина ограничивается половиной размера изображения, чтобы рамка не перекрывала всё изображение:
  ```python
  fw = min(frame_width, h // 2 + (h % 2), w // 2 + (w % 2))
  ```
- Цвет нормализуется по модулю 256 и конвертируется из RGB в BGR (для совместимости с OpenCV):
  ```python
  color = tuple(int(c) % 256 for c in color)
  color = (color[2], color[1], color[0])  # RGB → BGR
  ```
- Создаётся копия изображения: `result = image.copy()`.
- Рамка рисуется через заполнение четырёх полос с использованием срезов NumPy:
  ```python
  result[:fw, :] = color          # верхняя полоса
  result[h - fw:h, :] = color      # нижняя полоса
  result[:, :fw] = color           # левая полоса
  result[:, w - fw:w] = color      # правая полоса
  ```

**Математическая формула:**
```
Для области рамки:
  result[0:fw, :] = color                    # верх
  result[h-fw:h, :] = color                  # низ
  result[:, 0:fw] = color                     # лево
  result[:, w-fw:w] = color                   # право
```

### 8. Frame (curvy)

**Алгоритм (процедурная рамка):**
- По умолчанию рисует волнистую рамку (`frame_type="wave"`).
- Вычисляются параметры волны:
  ```python
  amplitude = max(2, frame_width)  # амплитуда волны
  period = max(20, min(w, h) // 4)  # период волны
  ```
- Для каждой стороны вычисляется синусоидальное смещение:
  - **Верхняя и нижняя границы:** для каждого `x` вычисляется `y`:
    ```python
    offset = amplitude * 0.5 * (1 + sin(2π * x / period))
    top_y = int(offset)
    bottom_y = h - 1 - int(offset)
    ```
  - **Левая и правая границы:** для каждого `y` вычисляется `x`:
    ```python
    offset = amplitude * 0.5 * (1 + sin(2π * y / period))
    left_x = int(offset)
    right_x = w - 1 - int(offset)
    ```
- Формируются массивы точек для каждой стороны.
- Контуры рисуются через алгоритм Брезенхема (`_draw_polyline_numpy`), который:
  - Соединяет последовательные точки линиями
  - Использует алгоритм Брезенхема для рисования каждой линии
  - Поддерживает заданную толщину линии через заполнение квадратов вокруг точек

**Алгоритм (внешняя рамка):**
- При активированной опции используется метод `OverlayProcessor.apply_overlay`.
- Внешнее изображение рамки (PNG с альфа-каналом) масштабируется к размеру изображения через `apply_linear_resize`.
- Накладывается поверх изображения с учётом альфа-канала.

**Математическая формула (синусоидальная рамка):**
```
Для верхней/нижней границы:
  y(x) = amplitude * 0.5 * (1 + sin(2π * x / period))

Для левой/правой границы:
  x(y) = amplitude * 0.5 * (1 + sin(2π * y / period))
```


### 9. Glare (блики объектива)

**Алгоритм (процедурный блик):**
- Базовый режим строит радиальную маску для создания белого блика вокруг центра.
- Пользователь может выбрать центр `(center_x, center_y)` кликом по изображению, задать радиус `radius` и интенсивность `intensity` (0.0-1.0).
- Координаты центра ограничиваются границами изображения.
- Создаётся сетка координат: `y, x = np.indices((h, w), dtype=np.float32)`.
- Вычисляются расстояния от каждого пикселя до центра:
  ```python
  distances = np.sqrt((x - center_x) ** 2 + (y - center_y) ** 2)
  ```
- Создаётся маска с квадратичным затуханием:
  ```python
  mask = np.clip(1.0 - (distances / radius), 0.0, 1.0)
  mask = mask ** 2  # квадратичное затухание для плавности
  ```
- Маска умножается на интенсивность и применяется к изображению:
  ```python
  flare = mask * intensity * 255.0
  result = image.astype(np.float32) + flare
  result = np.clip(result, 0, 255).astype(np.uint8)
  ```

**Алгоритм (текстура блика):**
- Если загружена текстура PNG с альфа-каналом, вызывается `OverlayProcessor.apply_overlay_centered`.
- Текстура приводится к формату BGRA (если отсутствует альфа-канал, добавляется непрозрачный).
- При необходимости масштабируется встроенным линейным ресайзом с учётом параметра `overlay_scale`.
- Вычисляется область наложения с учётом центрирования:
  ```python
  half_w = overlay_w // 2
  half_h = overlay_h // 2
  x1 = center_x - half_w
  y1 = center_y - half_h
  ```
- Область обрезается границами изображения.
- Альфа-канал умножается на коэффициент интенсивности.
- Выполняется альфа-композитинг: `blended = overlay * alpha + base * (1 - alpha)`.

**Математическая формула (процедурный блик):**
```
distance(x, y) = sqrt((x - cx)² + (y - cy)²)
mask = max(0, min(1, (1 - distance / radius)²))
flare = mask * intensity * 255
result = image + flare
```


### 10. Watercolor Paper Texture

**Алгоритм:**
- Требуется внешняя текстура (PNG изображение) — без неё фильтр не запускается.
- Текстура приводится к размеру исходного изображения через `apply_linear_resize`.
- Обработка альфа-канала:
  - Если текстура имеет альфа-канал (RGBA), он извлекается и нормализуется: `alpha = overlay[..., 3] / 255.0`.
  - Если альфа отсутствует (RGB или grayscale), она вычисляется из яркости:
    ```python
    alpha = ColorConverter.bgr_to_gray(texture_bgr) / 255.0
    ```
- Создаётся карта прозрачности с учётом интенсивности:
  ```python
  alpha_map = np.clip(alpha_channel * texture_intensity, 0.0, 1.0)
  ```
- Для цветных изображений альфа-карта расширяется по каналам: `alpha_map[..., np.newaxis]`.
- Выполняется альфа-композитинг между оригинальным изображением и текстурой:
  ```python
  blended = image_bgr * (1.0 - alpha_map) + texture_bgr * alpha_map
  ```
- Результат обрезается до диапазона `[0, 255]` и приводится к типу `uint8`.

**Математическая формула:**
```
alpha_map = alpha_texture * intensity
result = image * (1 - alpha_map) + texture * alpha_map
```

### 11. Overlay (альфа-композитинг)

**Алгоритм (`OverlayProcessor.apply_overlay`):**
- Универсальный метод для наложения изображений с учётом альфа-канала.
- Если размеры базового и накладываемого изображений отличаются, накладываемое изображение масштабируется через `apply_linear_resize`.
- Обработка альфа-канала:
  - Если накладываемое изображение имеет 3 канала (RGB), создаётся непрозрачный альфа: `alpha = 1.0`.
  - Если имеет 4 канала (RGBA), альфа извлекается и нормализуется: `alpha = overlay[..., 3] / 255.0`.
- Выполняется альфа-композитинг:
  ```python
  blended = overlay_bgr * alpha + base_bgr * (1.0 - alpha)
  ```
- Обработка различных форматов:
  - **Grayscale базовое изображение:** результат конвертируется обратно в grayscale через `ColorConverter.bgr_to_gray`.
  - **RGBA базовое изображение:** пересчитывается результирующий альфа-канал:
    ```python
    out_alpha = overlay_alpha + (1 - overlay_alpha) * base_alpha
    ```
    Результат объединяется: `np.dstack((blended, out_alpha))`.

**Алгоритм (`OverlayProcessor.apply_overlay_centered`):**
- Накладывает изображение по центру без растягивания.
- Вычисляется область наложения с учётом центрирования и границ изображения.
- Если текстура выходит за границы, обрезается только видимая часть.
- Поддерживает масштабирование текстуры через параметр `scale`.
- Альфа-канал умножается на параметр `intensity` для контроля прозрачности.

**Математическая формула:**
```
alpha = overlay_alpha / 255.0  (нормализация)
result = overlay * alpha + base * (1 - alpha)

Для RGBA:
  out_alpha = overlay_alpha + (1 - overlay_alpha) * base_alpha
```

## Особенности графического интерфейса
- Отображение исходного и обработанного кадра, гистограммы каналов с независимыми чекбоксами R/G/B.
- Динамическая панель параметров: слайдеры синхронизированы со спинбоксами, параметры валидируются.
- Поддержка выбора координат мышью (центр блика, виньетки, прямоугольник для пикселизации).
- Внешние текстуры отображаются миниатюрой.
- Результат можно сохранить или открыть во внешнем просмотрщике; временные копии пишутся в `%temp%`.
- Все преобразования цветов для отображения выполняются через `ColorConverter`.

## Соответствие требованиям задания

| Требование                    | Реализация                                                                                    |
| ----------------------------- | --------------------------------------------------------------------------------------------- |
| Функция изменения разрешения  | `apply_Nearest_Neighbor_interpolation`, `apply_Bilinear_interpolation`, `apply_linear_resize` |
| Сепия                         | `apply_sepia`                                                                                 |
| Виньетка                      | `apply_vignette`                                                                              |
| Пикселизация области          | `apply_pixelation`                                                                            |
| Прямоугольная рамка           | `apply_frame_simple`                                                                          |
| Фигурная рамка                | `apply_frame_curvy` (с поддержкой внешних текстур)                                            |
| Блики                         | `apply_glare` (с поддержкой внешних текстур)                                                  |
| Текстура акварельной бумаги   | `apply_watercolor_texture` (только внешние текстуры)                                          |
| README с описанием алгоритмов | текущий документ                                                                              |
| Демонстрация работы           | `main.py`                                                                                     |


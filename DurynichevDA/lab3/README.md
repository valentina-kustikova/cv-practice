# Практическая работа №3. Классификация изображений с использованием библиотеки OpenCV

---

## Цель работы

Разработать приложение для классификации изображений трёх достопримечательностей Нижнего Новгорода:
- Нижегородский Кремль
- Архангельский собор
- Дворец труда

Реализованы и сравниваются два подхода:
1. **Классический метод «мешок визуальных слов» (Bag of Visual Words, BoVW)**  
   с использованием детекторов SIFT, ORB, AKAZE и SVM-классификатора
2. **Нейросетевой подход** на основе Transfer Learning (EfficientNetB0) с визуализацией Grad-CAM

Данные доступны по [ссылке на набор данных](https://cloud.unn.ru/s/2KsWFmaxzZf9mF5) (включая файл с источниками для ExtDataset). Разбиение на выборки — по [ссылке](https://cloud.unn.ru/s/5rakAsHxweBi6qD). Дополнительные изображения не добавлялись, использовался исходный набор.

---

## Структура проекта
```
DutynichevDA/
└── lab3/
    ├── main.py              ← единый скрипт запуска (все команды)
    ├── data_loader.py       ← загрузка датасета и разбиения
    ├── detectors.py         ← ООП-классы: SIFTDetector, ORBDetector, AKAZEDetector
    ├── bow_classifier.py    ← BoW + MiniBatchKMeans + SVM (поддержка 3 детекторов)
    ├── nn_classifier.py     ← EfficientNetB0 (Fine-tuning)
    ├── train.txt
    ├── models/              ← автоматически создаётся
    │   ├── bow_sift_model.pkl
    │   ├── bow_orb_model.pkl
    │   ├── bow_akaze_model.pkl
    │   └── nn_model.keras
    ├── data/
    │   ├── ExtDataset/
    │   └── NNSUDataset/
    └── README.md 
```
---

## Архитектура приложения

Приложение построено по принципам ООП:
- Детекторы вынесены в отдельные классы (`detectors.py`)
- BoW и нейросеть — независимые модули
- Единая точка входа — `main.py` с удобным CLI
- Автоматическое сохранение/загрузка моделей

---

## Описание алгоритма Bag of Words

### Что такое Bag of Words
Мешок визуальных слов — это способ превратить изображение в гистограмму частот характерных локальных паттернов, полностью игнорируя их взаимное расположение, как будто мы высыпали все детали фото в мешок и просто посчитали, сколько каких попалось
### Этапы работы:
1. Извлечение локальных дескрипторов (SIFT / ORB / AKAZE)
2. Кластеризация всех дескрипторов → словарь из 600 визуальных слов (MiniBatchKMeans)
3. Построение гистограммы частот слов для каждого изображения
4. Нормализация + обучение линейного SVM

### Исследованные детекторы:
| Детектор | Особенности                                 | Цвет в визуализации |
|---------|---------------------------------------------|---------------------|
| SIFT    | Высокая точность, инвариантность к масштабу | Красный             |
| AKAZE   | Нелинейное масштабное пространство          | Зелёный             |
| ORB     | Быстрый, бинарный, открытый                 | Оранжевый           |

---

## Результаты экспериментов
### Описание метрик качества

Для оценки качества классификации используются следующие метрики:

* Accuracy (Точность) - доля правильно классифицированных изображений от общего числа. Показывает общую эффективность модели.

* Precision (Определенность) - доля истинно положительных предсказаний среди всех положительных предсказаний модели. Отвечает на вопрос: "Из всех изображений, которые модель отнесла к классу X, сколько действительно принадлежат этому классу?"

* Recall (Полнота) - доля истинно положительных предсказаний среди всех реальных положительных примеров. Отвечает на вопрос: "Из всех изображений класса X, сколько модель смогла правильно распознать?"

* F1-score - гармоническое среднее между Precision и Recall. Балансирует между точностью и полнотой, особенно полезен при несбалансированных классах.

* Macro average - среднее арифметическое метрик по всем классам (каждый класс имеет равный вес).

* Weighted average - взвешенное среднее метрик, где вес каждого класса пропорционален количеству его примеров в тестовой выборке.


### Сравнение точности классификации

| Метод                              | Детектор / Архитектура | Accuracy | Precision (macro) | Recall (macro) | F1-score (macro) |
|------------------------------------|------------------------|----------|-------------------|----------------|------------------|
| Bag of Visual Words + SVM          | **SIFT**               | **90%**  | 0.89              | 0.88           | 0.88             |
| Bag of Visual Words + SVM          | **AKAZE**              | **92%**  | 0.92              | 0.90           | 0.91             |
| Bag of Visual Words + SVM          | ORB                    | **77%**  | 0.75              | 0.72           | 0.73             |
| **EfficientNetB0 (Fine-tuning)**   | —                      | **100%** | 1.00              | 1.00           | 1.00             |

**Вывод по таблице:**  
- Лучший классический метод — **BoW + AKAZE** (92%)  
- На втором месте — **BoW + SIFT** (90%)  
- Нейросеть **EfficientNetB0** уверенно лидирует с результатом **100%**

**Вывод:** Нейросеть значительно превосходит классические методы, но BoW с SIFT/AKAZE даёт отличные результаты даже на CPU.

---

## Grad-CAM — интерпретация предсказаний нейросети



Для объяснения работы обученной модели EfficientNetB0 реализована техника **Grad-CAM** (Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization).

### Как работает Grad-CAM
1. Берётся предсказание сети для конкретного изображения и нужного класса (в нашем случае — тот класс, который сеть выбрала с максимальной уверенностью).
2. Вычисляются градиенты выхода (логита) этого класса по карте активаций последнего сверточного слоя (`top_conv` в EfficientNetB0).
3. Градиенты усредняются по каналам → получаем «веса важности» каждого канала.
4. Взвешенная сумма карт активаций умножается на эти веса → тепловая карта (heatmap).
5. Тепловая карта накладывается на исходное изображение с полупрозрачностью.

### Что мы видим на наших данных

Нейросеть **чётко фокусируется на архитектурно значимых деталях**:
- **Кремль** — зубцы стен, башни, красный кирпич, флаги
- **Архангельский собор** — золотые купола, кресты, белокаменные элементы
- **Дворец труда** — колонны, портик, симметричный фасад, часы

Во всех случаях область максимального внимания (ярко-красная/жёлтая на тепловой карте) точно соответствует ключевым отличительным признакам объекта.

### Преимущества Grad-CAM в данной работе
- Доказывает, что модель «смотрит» не на фон, небо или случайные текстуры, а именно на объект
- Уверенность предсказаний в экспериментах составляла **97.2 – 99.9 %**
- Позволяет визуально обосновать превосходство нейросетевого подхода над BoW

> Реализация выполнена без дополнительных библиотек — только TensorFlow/Keras + OpenCV.

---

## Запуск программы

Единый скрипт: `main.py`

```bash
# ВИЗУАЛИЗАЦИЯ КЛЮЧЕВЫХ ТОЧЕК
python main.py --visualize sift
python main.py --visualize orb
python main.py --visualize akaze

# GRAD-CAM — тепловая карта внимания нейросети
python main.py --visualize gradcam

# BAG OF WORDS — обучение + тест
python main.py --algo bow --mode both --detector sift
python main.py --algo bow --mode both --detector akaze
python main.py --algo bow --mode both --detector orb

# Только тест BoW
python main.py --algo bow --mode test --detector sift
python main.py --algo bow --mode test --detector akaze
python main.py --algo bow --mode test --detector orb

# НЕЙРОСЕТЬ
python main.py --algo nn --mode both      # обучение + тест
python main.py --algo nn --mode test

# ВСЁ СРАЗУ
python main.py --algo both --mode both
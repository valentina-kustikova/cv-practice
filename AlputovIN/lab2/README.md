# Практическая работа №2. Детектирование объектов на изображениях с использованием библиотеки OpenCV

## Описание

В данной работе реализовано приложение для детектирования транспортных средств на изображениях с использованием трёх различных нейросетевых моделей:
- **YOLOv8** (ONNX)
- **Faster R-CNN** (TensorFlow)
- **NanoDet-Plus** (ONNX)

Пользователь выбирает модель и путь к изображениям через аргументы командной строки. Детекторы реализованы в виде иерархии классов. Для каждой модели предусмотрены индивидуальные методы пред- и постобработки.

## Структура проекта

```text
lab2/
├── detectors/
│   ├── __init__.py          # Инициализация пакета
│   ├── base.py              # Базовый класс детектора
│   ├── detector_factory.py  # Фабрика детекторов
│   ├── yolov8.py            # Реализация YOLOv8
│   ├── fasterrcnn.py        # Реализация Faster R-CNN
│   └── nanodet.py           # Реализация NanoDet-Plus
├── data/                    # Изображения и разметка
├── detectors/models/        # Веса моделей (скачиваются автоматически)
├── main.py                  # Основной скрипт запуска
├── utils.py                 # Утилиты (IoU, метрики, визуализация)
├── download_models.py       # Скрипт скачивания моделей
└── README.md                # Документация
```

## Установка и запуск

### 1. Установка зависимостей

Для работы приложения необходимы Python 3.8+ и следующие библиотеки:

```bash
pip install opencv-python numpy
```

### 2. Скачивание моделей

Перед первым запуском необходимо скачать веса нейронных сетей:

```bash
python download_models.py
```

### 3. Запуск приложения

Примеры запуска для разных моделей:

```bash
# YOLOv8
python main.py --model yolov8 --images data/imgs_MOV03478 --show

# Faster R-CNN
python main.py --model fasterrcnn --show

# NanoDet-Plus
python main.py --model nanodet --show
```

## Параметры командной строки

Скрипт `main.py` поддерживает следующие аргументы:

| Параметр | Тип | По умолчанию | Описание |
| :--- | :--- | :--- | :--- |
| `--images` | str | `data/imgs_MOV03478` | Путь к папке с входными изображениями |
| `--annotations` | str | `data/mov03478.txt` | Путь к файлу разметки (Ground Truth) |
| `--model` | str | **Обязательный** | Выбор архитектуры модели: `yolov8`, `fasterrcnn`, `nanodet` |
| `--show` | flag | `False` | Флаг визуализации. Если указан, открывается окно с отрисовкой детекций |

Управление при просмотре (с флагом `--show`):
- Нажмите любую клавишу для перехода к следующему кадру (при `cv2.waitKey(0)`).
- Программа автоматически проходит по кадрам при `cv2.waitKey(1)`.

---

## Описание моделей и алгоритмов

### 1. YOLOv8 (You Only Look Once v8)

Современный одностадийный детектор (One-stage anchor-free), работающий в формате ONNX.

**Характеристики:**
- **Входной размер:** $640 \times 640$
- **Формат модели:** ONNX

**Предобработка:**
1. **Letterbox Resize:** Изображение масштабируется с сохранением пропорций, оставшееся место заполняется серым цветом (114, 114, 114).
2. **Нормализация:** Значения пикселей делятся на 255.0 (диапазон $[0, 1]$).
3. **SwapRB:** Конвертация цветового пространства $BGR \to RGB$.

**Формат выхода и постобработка:**
Выходной тензор имеет размерность `[1, 84, 8400]`.
- **84 канала:** 4 координаты bbox ($c_x, c_y, w, h$) + 80 вероятностей классов COCO.
- **8400 якорей:** Сумма ячеек сетки на разных масштабах (strides).

Алгоритм парсинга:
1. Тензор транспонируется к виду `[8400, 84]`.
2. Выбирается класс с максимальной вероятностью.
3. Отсеиваются детекции с `confidence < threshold`.
4. Координаты ($c_x, c_y, w, h$) преобразуются в углы ($x_1, y_1, x_2, y_2$).
5. Применяется **NMS** (Non-Maximum Suppression) для удаления дублей.

### 2. Faster R-CNN (Region-based Convolutional Neural Network)

Классический двухстадийный детектор. Используется архитектура с Inception v2 backbone.

**Характеристики:**
- **Входной размер:** $600 \times 600$
- **Формат модели:** TensorFlow Frozen Graph (`.pb` + `.pbtxt`)

**Предобработка:**
1. Используется `cv2.dnn.blobFromImage`.
2. Ресайз до $600 \times 600$.
3. Конвертация $BGR \to RGB$.
4. Внутренняя нормализация модели.

**Формат выхода и постобработка:**
Выходной тензор имеет размерность `[1, 1, N, 7]`.
Где `N` — количество обнаруженных боксов, а 7 значений вектора это:
`[batch_id, class_id, confidence, left, top, right, bottom]`

Алгоритм парсинга:
1. Фильтрация по `confidence`.
2. Фильтрация по `class_id` (оставляем только транспорт).
3. Координаты приходят нормализованными ($[0, 1]$), их необходимо умножить на ширину и высоту исходного изображения.

### 3. NanoDet-Plus

Сверхлегкий детектор для мобильных устройств, использующий стратегию Generalized Focal Loss (GFL).

**Характеристики:**
- **Входной размер:** $416 \times 416$
- **Формат модели:** ONNX

**Предобработка:**
1. Ресайз до $416 \times 416$.
2. **Нормализация** по среднему и стандартному отклонению:
   $$pixel' = \frac{pixel - \text{mean}}{\text{std}}$$
   Где $\text{mean}=[103.53, 116.28, 123.675]$, $\text{std}=[57.375, 57.12, 58.395]$.

**Формат выхода и постобработка:**
Модель возвращает предсказания для трех уровней страйдов (8, 16, 32). Выход содержит вероятности классов и регрессионные параметры GFL.

Алгоритм парсинга (GFL Decoding):
1. Для каждой стороны бокса предсказывается распределение вероятностей расстояния.
2. Вычисляется ожидаемое значение смещения через интеграл (Softmax + взвешенная сумма).
3. Восстанавливаются координаты относительно центра ячейки сетки.
4. Результаты со всех уровней объединяются и фильтруются через NMS.

---

## Методика оценки качества

Качество работы детекторов оценивается путем сравнения полученных результатов с эталонной разметкой (Ground Truth).

### 1. Критерий совпадения (IoU)

Для определения того, верно ли найден объект, используется метрика **Intersection over Union**:

$$IoU = \frac{\text{Площадь пересечения}}{\text{Площадь объединения}} = \frac{Area(A \cap B)}{Area(A \cup B)}$$

Детекция считается верной (**True Positive**), если:
1. Класс предсказанного объекта совпадает с классом в разметке.
2. Значение $IoU \ge 0.5$.

### 2. Рассчитываемые метрики

**TPR (True Positive Rate)** — Полнота (Recall).
Показывает, какую долю реальных объектов удалось обнаружить модели.

$$TPR = \frac{TP}{TP + FN}$$

*   $TP$ (True Positive) — верно обнаруженные объекты.
*   $FN$ (False Negative) — пропущенные объекты (существуют в разметке, но модель их не нашла).
*   *Интерпретация:* Если $TPR \approx 1.0$, модель находит почти все машины.

**FDR (False Discovery Rate)** — Доля ложных срабатываний.
Показывает процент "мусорных" предсказаний среди всех детекций модели.

$$FDR = \frac{FP}{TP + FP}$$

*   $FP$ (False Positive) — ложные срабатывания (модель нашла объект там, где его нет, или сильно ошиблась с координатами/классом).
*   *Интерпретация:* Если $FDR \approx 0.0$, модель редко ошибается. Высокий FDR означает, что модель "галлюцинирует".

---

## Результаты экспериментов

В таблице представлены результаты запуска моделей на тестовой последовательности кадров.

| Модель | TPR (Полнота) | FDR (Ложные сраб.) | Комментарий |
| :--- | :---: | :---: | :--- |
| **YOLOv8** | 0.XXX | 0.XXX | *Заполняется после запуска* |
| **Faster R-CNN** | 0.XXX | 0.XXX | *Заполняется после запуска* |
| **NanoDet-Plus** | 0.XXX | 0.XXX | *Заполняется после запуска* |

### Выводы
*Раздел предназначен для выводов после получения экспериментальных данных.*

---

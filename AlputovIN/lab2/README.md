
# Практическая работа №2. Детектирование объектов на изображениях с использованием библиотеки OpenCV

## Описание

В данной работе реализовано приложение для детектирования транспортных средств на изображениях с использованием трёх различных нейросетевых моделей:
- **YOLOv8** (ONNX) — современный Anchor-Free детектор.
- **YOLOv4** (Darknet) — классический высокоточный детектор.
- **NanoDet-Plus** (ONNX) — легковесная модель для мобильных устройств.

Пользователь выбирает модель и путь к изображениям через аргументы командной строки. Детекторы реализованы в виде иерархии классов. Для каждой модели предусмотрены индивидуальные методы пред- и постобработки (resize, normalization, decoding).

## Структура проекта

```text
lab2/
├── detectors/
│   ├── __init__.py          # Инициализация пакета
│   ├── base.py              # Базовый класс детектора
│   ├── detector_factory.py  # Фабрика детекторов
│   ├── yolov8.py            # Реализация YOLOv8
│   ├── yolov4.py            # Реализация YOLOv4 (Darknet)
│   └── nanodet.py           # Реализация NanoDet-Plus
├── data/                    # Изображения и разметка
├── detectors/models/        # Веса моделей (скачиваются автоматически)
├── main.py                  # Основной скрипт запуска
├── utils.py                 # Утилиты (IoU, метрики, визуализация)
├── download_models.py       # Скрипт скачивания моделей
└── README.md                # Документация
```

## Установка и запуск

### 1. Установка зависимостей

Для работы приложения необходимы Python 3.8+ и следующие библиотеки:

```bash
pip install opencv-python numpy
```

### 2. Скачивание моделей

Перед первым запуском необходимо скачать веса нейронных сетей (скрипт автоматически загрузит файлы в `detectors/models/`):

```bash
python download_models.py
```

### 3. Запуск приложения

Примеры запуска для разных моделей:

```bash
# YOLOv4 (тест на 100 случайных кадрах)
python main.py --model yolov4 --limit 100

# YOLOv8 (тест на всех кадрах с визуализацией)
python main.py --model yolov8 --limit 0 --show

# NanoDet-Plus
python main.py --model nanodet --limit 50 --show
```

## Параметры командной строки

Скрипт `main.py` поддерживает следующие аргументы:

| Параметр | Тип | По умолчанию | Описание |
| :--- | :--- | :--- | :--- |
| `--images` | str | `data/imgs_MOV03478` | Путь к папке с изображениями |
| `--annotations` | str | `data/mov03478.txt` | Путь к файлу разметки (Ground Truth) |
| `--model` | str | **Обязательный** | Выбор архитектуры: `yolov8`, `yolov4`, `nanodet` |
| `--limit` | int | `100` | Кол-во изображений для теста (0 = все) |
| `--show` | flag | `False` | Включить визуализацию |

Управление при просмотре (с флагом `--show`):
- `ESC` или `Q` — Выход из программы.
- `Пробел` — Пауза/Продолжить воспроизведение.

---

## Описание моделей и алгоритмов

### 1. YOLOv8 (You Only Look Once v8)

Современный **Anchor-Free** детектор.
- **Вход:** $640 \times 640$.
- **Предобработка:** Letterbox (масштабирование с сохранением пропорций и заполнением полей).
- **Постобработка:** Модель выдает 8400 кандидатов. Выполняется фильтрация по Confidence > 0.5 и Non-Maximum Suppression (NMS).

### 2. YOLOv4 (You Only Look Once v4)

Классический высокоточный детектор на базе архитектуры **CSPDarknet53**.
- **Вход:** $608 \times 608$.
- **Предобработка:** Масштабирование, нормализация ($pixel / 255.0$), SwapRB ($BGR \to RGB$).
- **Постобработка:** Модель имеет 3 выходных слоя (разные масштабы сетки). Координаты приходят относительными ($0..1$), конвертируются в абсолютные пиксели. Используется NMS для объединения рамок.

### 3. NanoDet-Plus

Сверхлегкий мобильный детектор, использующий стратегию **Generalized Focal Loss (GFL)**.
- **Вход:** $416 \times 416$.
- **Предобработка:** Нормализация по среднему и стандартному отклонению (ImageNet statistics).
- **Постобработка:** Декодирование вероятностного распределения координат (Integral Representation) вместо прямой регрессии боксов.

---

## Методика оценки качества

Качество работы детекторов оценивается путем сравнения полученных результатов с эталонной разметкой (Ground Truth).

1.  **Критерий совпадения (IoU):** Детекция считается верной (**True Positive**), если класс совпадает и $IoU \ge 0.5$.
2.  **TPR (True Positive Rate) / Полнота:**
    $$TPR = \frac{TP}{TP + FN}$$
    Показывает долю реально найденных объектов (чувствительность).
3.  **FDR (False Discovery Rate) / Доля ошибок:**
    $$FDR = \frac{FP}{TP + FP}$$
    Показывает процент "мусорных" предсказаний среди всех детекций.

## Результаты экспериментов

В таблице приведены результаты тестирования на выборке из 100 случайных кадров видеопоследовательности.

| Модель | TPR (Полнота) | FDR (Ложные сраб.) |
| :--- | :---: | :---: |
| **YOLOv4** | **0.955** | 0.325 |
| **YOLOv8** | 0.953 | **0.267** |
| **NanoDet-Plus** | 0.863 | 0.167 |


### Анализ результатов

#### 1. Сравнение YOLOv4 и YOLOv8
Обе модели показали практически идентичную полноту (**TPR ~0.95**), что является отличным результатом — обнаруживается 95% транспортных средств.
Однако **YOLOv8** продемонстрировала **меньший уровень ошибок (FDR 0.267 против 0.325)**. Это означает, что современная архитектура YOLOv8 (Anchor-Free) работает "чище", генерируя меньше ложных рамок и точнее описывая границы объектов, чем классическая v4.

#### 2. Проблема ложных срабатываний (FDR)
Значения FDR (26-32%) кажутся высокими, однако детальный анализ показывает, что значительная часть "ошибок" (False Positives) на самом деле является **верными детекциями объектов на дальнем плане**, которые просто отсутствуют в оригинальной разметке (Ground Truth). Модели оказываются "умнее" разметки.

#### 3. NanoDet-Plus
Модель показывает результат, характерный для легких сетей. Из-за низкого разрешения входа ($416 \times 416$) она пропускает мелкие объекты вдалеке (TPR ниже), но при этом имеет самый низкий FDR на крупных планах, работая очень уверенно по очевидным целям.

### Итоговые выводы

1.  **Лучший баланс:** **YOLOv8** является победителем теста. Она обеспечивает ту же высочайшую чувствительность, что и YOLOv4, но с меньшим количеством шума и ошибок.
2.  **Максимальная чувствительность:** **YOLOv4** всё еще актуальна и показывает результат на уровне современных SOTA моделей по способности находить объекты, но требует больше ресурсов и постобработки.
3.  **Скорость:** Для запуска на слабых устройствах (CPU, Raspberry Pi) рекомендуется **NanoDet-Plus**.
```

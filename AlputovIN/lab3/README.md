# Практическая работа №3. Классификация изображений с использованием библиотеки OpenCV

> **Внимание!** Датасет был удалён из репозитория. Перед использованием необходимо заново скачать датасет и разместить его в соответствующей папке data.

## Описание реализации

В данной работе реализованы два подхода к классификации изображений достопримечательностей Нижнего Новгорода:
1.  Метод "мешок слов" (Bag of Words, BoW) на основе SIFT + K-Means + SVM.
2.  Сверточная нейронная сеть (CNN) на основе архитектуры VGG16 с использованием трансферного обучения.

### Классифицируемые объекты:
- **01_NizhnyNovgorodKremlin** - Нижегородский Кремль
- **04_ArkhangelskCathedral** - Архангельский собор
- **08_PalaceOfLabor** - Дворец труда

---

## 1. Алгоритм "Мешок слов" (BoW)

### Этапы работы алгоритма:

#### 1.1 Извлечение локальных признаков
- Использование детектора **SIFT** (Scale-Invariant Feature Transform) для нахождения ключевых точек
- Вычисление SIFT-дескрипторов (128-мерные векторы) для каждой ключевой точки
- Дескрипторы инвариантны к масштабу, повороту и частично к изменению освещения

#### 1.2 Построение визуального словаря
- Сбор всех дескрипторов со всех обучающих изображений
- Кластеризация дескрипторов методом **K-means** (по умолчанию 100 кластеров)
- Центры кластеров становятся "визуальными словами" словаря

#### 1.3 Кодирование изображений
- Для каждого изображения: сопоставление дескрипторов с ближайшими визуальными словами
- Построение гистограммы частот визуальных слов
- Нормализация гистограммы (сумма = 1)

#### 1.4 Классификация
- Использование **SVM** (Support Vector Machine) классификатора с RBF ядром
- Обучение на полученных гистограммах
- Предсказание классов для новых изображений

### Параметры обучения:
-   **Детектор признаков**: `cv2.SIFT_create()` со стандартными параметрами.
-   **Размер словаря (K-Means)**: `n_clusters=100` (настраивается через `--clusters`).
-   **Классификатор (SVM)**: `SVC(kernel='rbf', probability=True)`.

### Преимущества метода BoW:
-  Инвариантность к масштабу и повороту
-  Не требует GPU
-  Хорошая интерпретируемость
-  Работает при малых датасетах


---

## 2. Нейросетевой подход (CNN)

### Архитектура:

#### 2.1 Базовая модель
- **VGG16** - предобученная на ImageNet (14 миллионов изображений, 1000 классов)
- Использование техники **Transfer Learning** (перенос обучения): сверточные слои VGG16 используются как экстрактор признаков, их веса "заморожены".

#### 2.2 Структура модели
- **Базовые слои VGG16**: заморожены (веса не изменяются)
- **Global Average Pooling**: уменьшение размерности
- **Dense (512, ReLU)**: полносвязный слой с 512 нейронами
- **Dropout (0.5)**: регуляризация для предотвращения переобучения
- **Dense (3, softmax)**: выходной слой для классификации 3 классов

#### 2.3 Предобработка изображений
- Изменение размера до 224×224 пикселей
- Конвертация BGR → RGB
- Нормализация значений пикселей для VGG16

### Параметры обучения и архитектуры:
*   **Размер входного изображения**: `(224, 224)` пикселей.
*   **Оптимизатор**: `Adam`.
*   **Скорость обучения (Learning Rate)**: `0.001` (настраивается через `--learning_rate`).
*   **Функция потерь**: `categorical_crossentropy`.
*   **Коэффициент Dropout**: `0.5` (настраивается через `--dropout_rate`).
*   **Количество эпох**: `10`.
*   **Размер батча (batch size)**: `16`.
*   **Валидационная выборка**: `20%` от обучающих данных.

### Преимущества CNN:
-  Автоматическое извлечение признаков
-  Высокая точность классификации
-  Учитывает пространственную структуру
-  Использует предобученные признаки ImageNet

### Недостатки CNN:
-  Требует GPU для быстрого обучения
-  Менее интерпретируем, чем BoW
-  Больше параметров модели

---

## 3. Структура проекта

```
lab3/
├── classifier/              # Пакет с классификаторами
│   ├── __init__.py
│   ├── base_classifier.py  # Базовый класс с общей логикой
│   ├── bow_classifier.py   # Реализация алгоритма "мешок слов"
│   └── cnn_classifier.py   # Реализация нейросетевого классификатора
├── data/                   # Директория с данными
│   ├── train.txt          # Список обучающих изображений
│   ├── test.txt           # Список тестовых изображений
│   ├── ExtDataset/        # Внешний датасет
│   └── NNSUDataset/       # Датасет ННГУ
├── bow_model/             # Сохраненные модели BOW классификатора
│   └── bow_model.joblib   # Модель (K-means + SVM + метаданные)
├── cnn_model/             # Сохраненные модели CNN классификатора
│   ├── cnn_model.h5       # Модель Keras/TensorFlow
│   └── metadata.npy       # Метаданные (class_names, label_encoder, image_size)

├── main.py                # Основной скрипт для запуска
└── README.md              # Документация
```

---

## 4. Установка и требования

### Необходимые библиотеки:

```bash
pip install opencv-python
pip install numpy
pip install scikit-learn
pip install tensorflow
pip install joblib
```

### Требования к системе:
- Python 3.7+
- Для CNN: рекомендуется GPU (но можно использовать CPU)

---

## 5. Использование

### 5.1 Входные параметры

| Параметр | Описание | Обязательный | По умолчанию |
|----------|----------|--------------|--------------|
| `--data_dir` | Путь к директории с изображениями | Да | - |
| `--train_file` | Путь к файлу со списком обучающих изображений | Да | - |
| `--test_file` | Путь к файлу со списком тестовых изображений | Да | - |
| `--mode` | Режим работы: `train`, `test`, `both` | Нет | `both` |
| `--algorithm` | Алгоритм: `bow`, `cnn`, `both` | Нет | `both` |
| `--model_dir` | Директория для сохранения/загрузки моделей | Нет | `bow_model` или `cnn_model` |
| `--clusters` | Количество кластеров для BoW | Нет | `100` |
| `--learning_rate` | Скорость обучения для CNN | Нет | `0.001` |
| `--dropout_rate` | Dropout rate для CNN | Нет | `0.5` |
| `--visualize` | Путь к изображению для визуализации SIFT-ключевых точек | Нет | - |
| `--visualize_output` | Путь для сохранения изображения с визуализацией | Нет | - |
| `--visualize_style` | Стиль отрисовки: `rich`, `simple`, `not_scaled` | Нет | `rich` |

### 5.2 Команды запуска

#### Тестирование BOW классификатора (с готовой моделью):

```bash
C:\venv_tf\Scripts\python "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\main.py" --data_dir "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\data" --train_file "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\data\train.txt" --test_file "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\data\test.txt" --mode test --algorithm bow
```

#### Тестирование CNN классификатора (с готовой моделью):

```bash
C:\venv_tf\Scripts\python "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\main.py" --data_dir "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\data" --train_file "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\data\train.txt" --test_file "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\data\test.txt" --mode test --algorithm cnn
```

#### Тестирование обоих классификаторов:

```bash
C:\venv_tf\Scripts\python "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\main.py" --data_dir "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\data" --train_file "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\data\train.txt" --test_file "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\data\test.txt" --mode test --algorithm both
```

#### Обучение и тестирование BOW классификатора:

```bash
C:\venv_tf\Scripts\python "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\main.py" --data_dir "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\data" --train_file "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\data\train.txt" --test_file "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\data\test.txt" --mode both --algorithm bow --clusters 100
```

#### Обучение и тестирование CNN классификатора:

```bash
C:\venv_tf\Scripts\python "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\main.py" --data_dir "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\data" --train_file "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\data\train.txt" --test_file "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\data\test.txt" --mode both --algorithm cnn --learning_rate 0.001 --dropout_rate 0.5
```

#### Визуализация SIFT-ключевых точек:

```bash
# Показать визуализацию на экране
C:\venv_tf\Scripts\python "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\main.py" --visualize "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\data\ExtDataset\01_NizhnyNovgorodKremlin\DSC_3184.jpg"

# Сохранить визуализацию в файл
C:\venv_tf\Scripts\python "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\main.py" --visualize "C:\opencv_lab2\cv-practice-lab1\AlputovIN\lab3\data\ExtDataset\01_NizhnyNovgorodKremlin\DSC_3184.jpg" --visualize_output "sift_visualization.jpg" --visualize_style rich
```

### 5.3 Формат файлов данных

Файлы `train.txt` и `test.txt` содержат относительные пути к изображениям, по одному на строку:

```
ExtDataset/01_NizhnyNovgorodKremlin/image1.jpg
NNSUDataset/04_ArkhangelskCathedral/image2.jpg
...
```

Пути указываются относительно директории, указанной в `--data_dir`.

### 5.4 Визуализация SIFT-ключевых точек

Для визуализации этапов работы алгоритма "мешок слов" можно использовать режим визуализации:

**Параметры визуализации:**
- `--visualize` - путь к изображению для анализа
- `--visualize_output` - путь для сохранения результата (опционально)
- `--visualize_style` - стиль отрисовки:
  - `rich` - полная визуализация с размерами и ориентацией (по умолчанию)
  - `simple` - простая отрисовка только точек
  - `not_scaled` - точки без масштабирования

**Пример использования:**
```bash
# Показать на экране
python main.py --visualize "data/ExtDataset/01_NizhnyNovgorodKremlin/DSC_3184.jpg"

# Сохранить в файл
python main.py --visualize "data/ExtDataset/01_NizhnyNovgorodKremlin/DSC_3184.jpg" --visualize_output "result.jpg"
```

```bash
=== Визуализация SIFT-ключевых точек ===

=== Анализ SIFT-дескрипторов для DSC_3184.jpg ===
Найдено ключевых точек: 1014
Средний размер области: 3.74 пикселей
Средний угол ориентации: 177.05 градусов
Средняя сила отклика: 0.0291
Размерность дескрипторов: (1014, 128)

Нажмите любую клавишу для закрытия окна...
```

При визуализации выводится статистика:
- Количество найденных ключевых точек
- Средний размер области дескриптора
- Средний угол ориентации
- Средняя сила отклика
- Размерность дескрипторов


---

## 6. Описание классов и методов

### 6.1 BaseClassifier

Базовый абстрактный класс, содержащий общую логику для всех классификаторов.

**Основные методы:**
- `detect_label_from_path(image_path)` - определяет метку класса из пути к файлу
- `load_data(data_file, data_dir)` - загружает данные из файла со списком изображений
- `load_image(image_path)` - загружает и предобрабатывает изображение
- `evaluate(y_true, y_pred, target_names)` - оценка качества классификации
- `train(train_paths, train_labels)` - абстрактный метод для обучения
- `test(test_paths, test_labels)` - абстрактный метод для тестирования

### 6.2 BOWClassifier

Реализация классификатора на основе метода "мешок слов".

**Основные методы:**
- `extract_features(image)` - извлекает SIFT-дескрипторы из изображения
- `build_vocabulary(all_descriptors)` - строит визуальный словарь с помощью K-means
- `descr_to_histogram(descriptors)` - преобразует дескрипторы в гистограмму визуальных слов
- `train(train_paths, train_labels)` - обучает модель BOW на предоставленных данных
- `test(test_paths, test_labels)` - тестирует модель на предоставленных данных
- `show_keypoints(image_path, output_path, draw_style)` - визуализирует SIFT-ключевые точки на изображении
- `save_model()` - сохраняет модель в файл `bow_model.joblib`
- `load_model()` - загружает модель из файла

**Сохранение модели:**
- Все данные сохраняются в одном файле `bow_model.joblib`:
  - `kmeans` - модель кластеризации (визуальный словарь)
  - `classifier` - SVM классификатор
  - `class_names` - названия классов
  - `n_clusters` - количество кластеров

### 6.3 CNNClassifier

Реализация классификатора на основе сверточной нейронной сети VGG16.

**Основные методы:**
- `create_model(n_classes)` - создает модель CNN на основе VGG16 с transfer learning
- `preprocess_image(image)` - предобрабатывает изображение для CNN
- `train(train_paths, train_labels)` - обучает CNN модель на предоставленных данных
- `test(test_paths, test_labels)` - тестирует CNN модель на предоставленных данных
- `save_model()` - сохраняет модель и метаданные
- `load_model()` - загружает модель и метаданные

**Сохранение модели:**
- `cnn_model.h5` - архитектура и веса нейросети (формат Keras)
- `metadata.npy` - метаданные:
- `class_names` - названия классов
- `label_encoder` - кодировщик меток (LabelEncoder)
- `image_size` - размер входных изображений

---

## 7. Результаты тестирования

### 7.1 Метод "Мешок слов" (BoW)

**Общая точность: 90.9%**

| Класс | Precision | Recall | F1-score | Support |
|-------|-----------|--------|----------|---------|
| Нижегородский Кремль | 0.93 | 1.00 | 0.96 | 39 |
| Архангельский собор | 0.88 | 0.70 | 0.78 | 20 |
| Дворец труда | 0.90 | 0.93 | 0.92 | 29 |
| **Среднее (macro)** | 0.90 | 0.88 | 0.89 | 88 |
| **Среднее (weighted)** | 0.91 | 0.91 | 0.91 | 88 |

**Анализ:**
- Лучший класс: Нижегородский Кремль (F1=0.96)
- Худший класс: Архангельский собор (F1=0.78, низкий recall=0.70)
- Модель пропускает около 30% изображений Архангельского собора

### 7.2 Нейросетевой классификатор (CNN)

**Общая точность: 97.7%**

| Класс | Precision | Recall | F1-score | Support |
|-------|-----------|--------|----------|---------|
| Нижегородский Кремль | 0.95 | 1.00 | 0.97 | 39 |
| Архангельский собор | 1.00 | 0.95 | 0.97 | 20 |
| Дворец труда | 1.00 | 0.97 | 0.98 | 29 |
| **Среднее (macro)** | 0.98 | 0.97 | 0.98 | 88 |
| **Среднее (weighted)** | 0.98 | 0.98 | 0.98 | 88 |

**Анализ:**
- Все классы показывают отличные результаты (F1 > 0.97)
- Наибольшее улучшение по сравнению с BoW в классе "Архангельский собор" (+0.19 F1-score)

### 7.3 Сравнение методов

| Метод | Общая точность | Преимущества | Недостатки |
|-------|----------------|--------------|------------|
| **BoW + SVM** | 90.9% | Не требует GPU, быстрая работа, хорошая интерпретируемость | Ниже точность, особенно для сложных объектов |
| **CNN (VGG16)** | 97.7% | Высокая точность, автоматическое извлечение признаков | Требует GPU для обучения, больше вычислительных ресурсов |

**Выводы:**
- CNN превосходит BoW на 6.8% по общей точности
- Наибольшая разница в классе "Архангельский собор": BoW F1=0.78, CNN F1=0.97
- CNN лучше справляется с извлечением признаков для сложных объектов

---

## 8. Использованные библиотеки

- **OpenCV (cv2)** - извлечение SIFT-дескрипторов, работа с изображениями
- **NumPy** - работа с массивами и матрицами
- **scikit-learn** - K-means кластеризация, SVM классификатор, метрики оценки
- **TensorFlow/Keras** - нейросетевой классификатор на основе VGG16
- **joblib** - сохранение и загрузка моделей BoW

---

## 9. Примечания

### О структуре данных:
- Изображения должны быть организованы в подпапках с названиями классов
- Названия классов определяются автоматически из структуры директорий
- Поддерживаются форматы: JPG, JPEG, PNG

### О моделях:
- BOW модель сохраняется в формате `joblib` (один файл со всеми данными)
- CNN модель сохраняется в формате Keras H5 (модель) + NumPy (метаданные)
- При загрузке модели автоматически определяются классы и параметры

### О производительности:
- BOW: обучение занимает несколько минут, тестирование - секунды
- CNN: обучение занимает 10-30 минут (зависит от GPU), тестирование - несколько секунд

---

```markdown
# Практическая работа №2. Детектирование объектов на изображениях с использованием библиотеки OpenCV

## Цель работы
Реализовать приложение для детектирования транспортных средств на последовательности кадров с использованием нейронных сетей из модуля cv.dnn библиотеки OpenCV.

Приложение должно:
- поддерживать несколько моделей (YOLOv4, SSD MobileNet, Faster R-CNN);
- иметь иерархию классов детекторов с разной пред- и постобработкой;
- загружать кадры из директории, сравнивать детекции с разметкой и считать метрики TPR и FDR;
- опционально отображать кадры с отрисованными прямоугольниками разных цветов для разных классов.

## Структура проекта
```
lab2_vehicle_detection/
├── README.md
├── main.py                # точка входа 
├── app.py                 # логика приложения
├── detector_base.py       # базовые структуры и абстрактный детектор
├── detector_factory.py    # фабрика детекторов и конфиги моделей
├── yolo_detector.py       # детектор YOLOv4
├── ssd_mobilenet_detector.py  # детектор SSD MobileNet
├── faster_rcnn_detector.py    # детектор Faster R-CNN
├── evaluator.py           # вычисление TPR и FDR
├── annotation_loader.py   # загрузка аннотаций
├── configs/
│   ├── coco.names                     # классы COCO
│   ├── ssd_mobilenet_v3_large_coco.pbtxt
│   ├── faster_rcnn_inception_v2_coco.pbtxt
│   └── yolov4.cfg
├── models/
│   ├── ssd_mobilenet_v3_large_coco_2020_01_14.pb
│   ├── frozen_inference_graph_faster_rcnn.pb
│   └── yolov4.weights
└── data/
    ├── images/          # кадры 
    └── annotations.txt  # файл разметки
```

## Алгоритмы детектирования

### 1. YOLOv4

**Предобработка изображения**
- изменение размера до 416×416 пикселей;
- нормализация пикселей: умножение на 1/255.0;
- формирование 4D-тензора через cv.dnn.blobFromImage с параметрами:
  - swapRB=True,
  - mean=(0, 0, 0),
  - crop=False.

**Прямое распространение**
- сеть загружается из yolov4.cfg и yolov4.weights;
- для получения выходов используются имена выходных слоёв;
- выполняется forward по этим слоям, выходы объединяются в массив детекций N × (4 + 1 + C).

**Постобработка**
- каждая детекция содержит:
  - нормализованные координаты центра и размеров бокса (x, y, w, h),
  - оценку objectness,
  - вероятности по классам;
- вычисляется итоговая уверенность:
  ```
  p_total = p_object ⋅ max(p_k)
  ```
- выбирается класс:
  ```
  ĉ = arg max(p_k)
  ```
- отбрасываются детекции с p_total < threshold;
- координаты переводятся к формату (x1, y1, x2, y2) и масштабируются к размеру исходного изображения;
- применяется Non-Maximum Suppression для удаления дубликатов.

### 2. SSD MobileNet

**Предобработка**
- изменение размера до 300×300;
- нормализация к диапазону [-1, 1]:
  - scale = 1/127.5, mean=(127.5, 127.5, 127.5), swapRB=True;
- формирование blob через cv.dnn.blobFromImage.

**Выход модели**
- формат outputs[0, 0, N, 7], где каждая запись: (batch_id, class_id, p, x_1, y_1, x_2, y_2) с координатами в нормализованном виде [0, 1].

**Постобработка**
- отбираются детекции с p ≥ threshold;
- координаты масштабируются:
  ```
  x_px = x ⋅ W, y_px = y ⋅ H
  ```
- применяется NMS на стороне базового класса.

### 3. Faster R-CNN

**Предобработка**
- изменение размера до 300×300;
- формирование blob без дополнительной нормализации;
- swapRB=True.

**Прямое распространение и постобработка**
- формат выходов такой же, как у SSD;
- порог по уверенности и масштабирование координат аналогичны SSD;
- NMS применяется в базовом классе.

## Методика оценки качества
Для оценки используются метрики:

**TPR:**
```
TPR = TP / (TP + FN)
```

**FDR:**
```
FDR = FP / (TP + FP)
```

Сопоставление предсказаний с разметкой выполняется по метрике Intersection over Union:

```
IoU(A,B) = |A ∩ B| / |A ∪ B| = |A ∩ B| / (|A| + |B| - |A ∩ B|)
```

**Критерий:**
- True Positive (TP) — если IoU ≥ 0.5 и класс совпадает;
- False Positive (FP) — детекция без подходящего GT;
- False Negative (FN) — GT-бокс, не покрытый ни одной детекцией.

Алгоритм реализован в evaluator.py:
- для каждого кадра детекции сортируются по убыванию уверенности;
- каждая детекция матчится с наилучшим GT-боксом, если IoU ≥ 0.5;
- обновляются глобальные счётчики TP, FP, FN;
- вычисляются кадровые TPR/FDR и агрегированные TPR/FDR.

## Визуализация
При отображении:
- каждая детекция рисуется прямоугольником:
  - цвет зависит от класса;
  - в левом верхнем углу прямоугольника отображается:
    - "<класс>: <уверенность>" с точностью до трёх знаков после запятой;
    - над прямоугольником дополнительно подписывается наблюдаемый класс объекта;
- Ground Truth-боксы рисуются фиолетовым цветом и помечаются подписью GT;
- в левом верхнем углу кадра выводятся текущие значения:
  - TPR, FDR,
  - Frame TPR, Frame FDR.

## Запуск приложения
Пример запуска из корня проекта:

```bash
python main.py \
    --images data/images \
    --annotations data/annotations.txt \
    --model yolo \
    --conf 0.5 \
    --show-gt
```

**Параметры:**
- `--images` — путь к директории с кадрами;
- `--annotations` — путь к текстовому файлу разметки;
- `--model` — одна из моделей: yolo, ssd, rcnn;
- `--conf` — порог уверенности детекций;
- `--no-display` — отключить показ окон OpenCV;
- `--show-gt` — отрисовывать Ground Truth-боксы.

## Метрики качества
После запуска выводятся итоговые значения:
- **TPR (True Positive Rate)** — доля правильно найденных машин;
- **FDR (False Discovery Rate)** — доля ложных срабатываний среди всех детекций.
```

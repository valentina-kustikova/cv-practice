# Практическая работа №3. Классификация изображений с использованием библиотеки OpenCV

Разработано приложение для классификации изображений трех достопримечательностей Нижнего Новгорода:`01_NizhnyNovgorodKremlin`, `04_ArkhangelskCathedral`, `08_PalaceOfLabor`. Приложение поддерживает два алгоритма классификации: **"Мешок Слов" (Bag-of-Words, BoW)** и нейронной сети на основе transfer learning (MobileNetV2).

---

## 1. Структура и Входные Параметры

Приложение реализовано в виде класса `ImageClassifier` в файле `lab3.py` и запускается из командной строки с использованием следующих аргументов:

| Аргумент | Тип | Описание | Пример |
| :--- | :--- | :--- | :--- |
| `--data_dir` | `str` | Путь к корневой директории с данными. | `data` |
| `--train_file` | `str` | Путь к файлу со списком тренировочных изображений. | `train.txt` |
| `--test_file` | `str` | Путь к файлу со списком тестовых изображений. | `test.txt` |
| `--mode` | `str` | Режим работы: `train`, `test` или `train,test`. | `train,test` |
| `--algorithm` | `str` | Используемый алгоритм: `bow` или `nn`. | `bow` |
| `--params` | `str` | Параметры алгоритма в формате JSON-строки. | `{"k": 100}` |

---

## 2. Алгоритмы Классификации

### 2.1. Алгоритм "Мешок Слов" (Bag-of-Words, BoW)

Алгоритм BoW преобразует изображение из набора локальных дескрипторов в глобальный вектор признаков (гистограмму), который затем используется для обучения классификатора.

#### Процесс Обучения BoW

1.  **Детектирование и извлечение дескрипторов:**
    * Для каждого тренировочного изображения используется **SIFT (Scale-Invariant Feature Transform)** для нахождения ключевых точек и извлечения 128-мерных дескрипторов.
    * Все дескрипторы со всех тренировочных изображений собираются в один большой массив.

2.  **Построение словаря (Codebook):**
    * К собранным дескрипторам применяется алгоритм кластеризации **$K$-Means**.
    * Параметр **$K$** (число кластеров) является размером словаря и задается в `--params` (по умолчанию $K=100$). Центроиды кластеров становятся "визуальными словами" словаря.

3.  **Вычисление гистограмм BoW:**
    * Для каждого изображения (тренировочного и тестового) дескрипторы сопоставляются с ближайшим "визуальным словом" (центроидом) из словаря.
    * Формируется **гистограмма** – вектор, в котором каждый элемент соответствует частоте появления соответствующего "визуального слова" в данном изображении.

4.  **Нормализация и классификация:**
    * Гистрограммы нормализуются с использованием **StandardScaler** для стандартизации признаков.
    * Обучается классификатор **Support Vector Classifier (SVC)** с линейным ядром на нормализованных тренировочных гистограммах и метках классов.

### 2.2. Нейросетевой Классификатор (CNN)

Используется подход **переноса обучения (Transfer Learning)**, что позволяет добиться высокого качества классификации на небольших наборах данных.

#### Процесс Обучения CNN

1.  **Выбор Базовой Модели:**
    * Используется предобученная на датасете ImageNet модель **MobileNetV2**. Эта модель уже научилась извлекать высокоуровневые признаки, полезные для общего распознавания изображений.

2.  **Модификация Архитектуры:**
    * Последний полносвязный слой (**классификатор**) MobileNetV2 заменяется на новый слой `nn.Linear`, имеющий **3 выхода**, что соответствует количеству классифицируемых классов.

3.  **Предобработка и Аугментация Данных:**
    * **Для тренировки (Training):** Применяются преобразования, включающие изменение размера до 224x224, **случайные повороты (RandomRotation)** и **случайные горизонтальные отражения (RandomHorizontalFlip)** для увеличения разнообразия данных. Далее выполняется преобразование в тензор и нормализация.
    * **Для тестирования (Testing):** Применяются только изменение размера, преобразование в тензор и нормализация.

4.  **Обучение Модели:**
    * В качестве функции потерь используется **CrossEntropyLoss**.
    * Оптимизатор **AdamW** используется для обновления весов.
    * Обучение производится на **10 эпохах** (значение из лога) с заданной скоростью обучения (`lr`) и размером батча (`batch_size`).
    * Используется GPU (`cuda`), если доступен, для ускорения процесса.

---

## 3. Результаты Классификации и Выводы

### 3.1. Результаты BoW (K=100)

| Класс | Precision (Точность) | Recall (Полнота, TPR) | F1-Score | Support |
| :--- | :--- | :--- | :--- | :--- |
| **01_NizhnyNovgorodKremlin** | 1.00 | 0.87 | 0.93 | 69 |
| **04_ArkhangelskCathedral** | 0.96 | 0.89 | 0.92 | 27 |
| **08_PalaceOfLabor** | 0.74 | **0.97** | 0.84 | 35 |
| **Macro Avg** | 0.90 | **0.91** | 0.90 | 131 |
| **Accuracy** | - | - | - | **0.9007** |

#### Вывод по BoW

* **Общее качество:** Модель BoW показала **высокую общую точность (Accuracy) 90.07%**.
* **Recall (TPR) для оценивания:** Средний показатель **Recall (Macro Avg)** составляет **0.91**.
* **Сильные стороны:**`01_NizhnyNovgorodKremlin` классифицируется с **идеальной точностью (1.00)**, т.е. ни одно предсказание этого класса не было ошибочным (высокий Precision).
* **Слабые стороны:**`08_PalaceOfLabor` имеет самый низкий **Precision (0.74)**, что означает, что модель часто ошибочно предсказывала этот класс, принимая за него другие объекты. В то же время, у него самый высокий **Recall (0.97)**, что говорит о том, что почти все фактические изображения класса были правильно найдены.
* Для повышения точности, возможно, следует увеличить число кластеров K.
### 3.2. Результаты CNN (MobileNetV2, 10 эпох)

| Метрика | Значение |
| :--- | :--- |
| **Test Accuracy** | **1.00** |

#### Вывод по CNN

* **Общее качество:** Нейросетевая модель с переносом обучения достигла **идеальной точности 100% (Test Accuracy: 1.0)** на тестовой выборке после 10 эпох обучения.
* **Recall (TPR) для оценивания:** Поскольку общая точность составляет 1.0, это означает, что **Recall (TPR)** для каждого класса также равен **1.0**.
* **Заключение:** Перенос обучения с использованием предобученной модели **MobileNetV2** оказался значительно эффективнее для данной задачи, полностью решив задачу классификации на предоставленном тестовом наборе. Это подтверждает рекомендацию об использовании переноса обучения для небольших наборов данных.

### Общий Вывод

| Метод | Test Accuracy | Macro Avg Recall (TPR) |
| :--- | :--- | :--- |
| **BoW (K=100)** | 0.90 | 0.91 |
| **CNN (MobileNetV2)** | **1.00** | **1.00** |

Для данной задачи классификации **сверточная нейронная сеть (CNN)** с использованием переноса обучения показала **превосходный результат (100% точность)**, значительно превзойдя классический алгоритм "Мешок Слов" (90% точность). Для достижения максимального качества классификации следует использовать нейросетевой подход.

---

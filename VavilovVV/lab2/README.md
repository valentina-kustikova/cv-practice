# Практическая работа №2. Детектирование объектов на изображениях с использованием библиотеки OpenCV

Этот проект представляет собой приложение для обнаружения транспортных средств на изображениях с использованием различных предварительно обученных моделей глубокого обучения через модуль **OpenCV DNN (Deep Neural Network)**. Приложение также включает функциональность для оценки производительности моделей.

-----

## Структура Проекта

Проект организован в виде модульной структуры:

```
.
├── detectors.py             # Фабрика детекторов и информация о моделях
├── detector_base.py         # Базовый класс детектора и структуры данных
├── yolo_detector.py         # Реализация постпроцессинга для YOLO
├── ssd_detector.py          # Реализация постпроцессинга для SSD MobileNet
├── rcnn_detector.py         # Реализация постпроцессинга для Faster R-CNN
├── utils.py                 # Утилиты для загрузки аннотаций, оценки метрик и визуализации
└── main.py                  # Основной исполняемый файл приложения
```

Для корректной работы требуются обученные модели в папке `models/` и изображения с аннотациями.

-----

## Классы и Функции

### `detector_base.py`

  * **`@dataclass Detection`**: Структура данных для хранения результата одного обнаружения.
      * `class_id`: ID класса (целое число).
      * `class_name`: Название класса (строка).
      * `confidence`: Уверенность обнаружения (вещественное число).
      * `bbox`: Ограничивающий прямоугольник $(x_1, y_1, x_2, y_2)$ (кортеж).
  * **`@dataclass ModelConfig`**: Структура данных для хранения параметров конфигурации модели.
      * Хранит пути, классы, размер ввода, факторы масштабирования, пороги и т.д.
  * **`class BaseDetector(ABC)`**: Абстрактный базовый класс для всех детекторов.
      * `__init__(self, config)`: Инициализирует модель с помощью `cv2.dnn.readNet()`.
      * `preprocess(self, image)`: Создает **BLOB** из изображения, используя параметры конфигурации.
      * `@abstractmethod postprocess(self, outputs, image_shape)`: **Абстрактный метод** для обработки сырых выходных данных сети и преобразования их в список объектов `Detection`.
      * `_apply_nms(self, detections)`: Применяет **Non-Maximum Suppression (NMS)** для удаления перекрывающихся ограничивающих прямоугольников. Использует `cv2.dnn.NMSBoxes()`.
      * `detect(self, image)`: Полный цикл обнаружения: `preprocess` $\to$ `net.forward()` $\to$ `postprocess` $\to$ `_apply_nms`.

### Реализации Детекторов

Детекторы наследуются от `BaseDetector` и реализуют специфический метод `postprocess`.

  * **`class YOLODetector` (в `yolo_detector.py`)**: Реализует постпроцессинг для моделей типа YOLO (например, YOLOv4/v4-tiny). Обрабатывает выходные данные, которые содержат координаты центра, ширину, высоту, уверенность объекта и вероятности классов.
  * **`class SSDMobileNetDetector` (в `ssd_detector.py`)**: Реализует постпроцессинг для моделей, основанных на SSD/MobileNet.
  * **`class FasterRCNNDetector` (в `rcnn_detector.py`)**: Реализует постпроцессинг для моделей, основанных на Faster R-CNN.

### Детекторы (`detectors.py`)

  * **`class VehicleDetectorFactory`**: Использует паттерн **Фабрика (Factory Pattern)** для создания экземпляров детекторов.
      * `_MODELS`: Приватный словарь, хранящий конфигурацию для всех доступных моделей (yolov4tiny, yolov4, mobilenet, rcnn).
      * `@staticmethod get_available_models()`: Возвращает список доступных моделей с кратким описанием.
      * `@staticmethod create_detector(model_type: str, confidence_threshold: float = 0.5) -> BaseDetector`: Создает и возвращает соответствующий объект детектора (`YOLODetector`, `SSDMobileNetDetector` или `FasterRCNNDetector`), используя конфигурацию из `_MODELS` и обертывая ее в `ModelConfig`.

### Утилиты (`utils.py`)

  * **`class AnnotationLoader`**: Загружает аннотации Ground Truth из файла.
      * `_load_annotations()`: Читает файл аннотаций и фильтрует только класс **"car"**, сохраняя ограничивающие прямоугольники в словарь, где ключ — ID изображения.
  * **`class DetectionEvaluator`**: Класс для расчета метрик обнаружения.
      * `calculate_iou(self, box1, box2) -> float`: Вычисляет **Intersection over Union (IoU)** между двумя ограничивающими прямоугольниками $B_1$ и $B_2$.
        $$\text{IoU}(B_1, B_2) = \frac{\text{Area}(B_1 \cap B_2)}{\text{Area}(B_1 \cup B_2)}$$
      * `evaluate_frame(...)`: Обновляет общее количество TP, FP, FN на основе детекций для одного кадра, используя **IoU Threshold** (по умолчанию 0.5) для сопоставления.
      * `get_metrics()`: Вычисляет **TPR** и **FDR** на основе накопленных TP, FP, FN.

#### Используемые Метрики Оценки

Оценка основана на подсчете:

  * **True Positives (TP)**: Детекция автомобиля, которая совпадает с Ground Truth (GT) с $\text{IoU} \ge 0.5$.
  * **False Positives (FP)**: Детекция автомобиля, которая не совпадает ни с одним неиспользованным GT, или детекция другого класса (в данном проекте учитываются только детекции класса 'car').
  * **False Negatives (FN)**: Объекты GT, которые не были обнаружены.

Из этих значений рассчитываются две основные метрики:

1.  **True Positive Rate (TPR)** или **Recall/Полнота**: Доля правильно обнаруженных объектов GT.
    $$\text{TPR} = \frac{\text{TP}}{\text{TP} + \text{FN}}$$
2.  **False Discovery Rate (FDR)**: Доля ложных обнаружений среди всех обнаружений.
    $$\text{FDR} = \frac{\text{FP}}{\text{TP} + \text{FP}}$$

### Основное Приложение (`main.py`)

  * **`class VehicleDetectionApp`**: Основной класс приложения.
      * `run(...)`: Инициализирует выбранный детектор и оценщик, затем циклически обрабатывает все изображения:
        1.  Загружает изображение и соответствующие аннотации GT.
        2.  Выполняет обнаружение (`detector.detect(image)`).
        3.  Вычисляет покадровые метрики (`evaluator.evaluate_frame(...)`).
        4.  Визуализирует результаты (обнаружения, GT и метрики) при включенном отображении.
        5.  Выводит финальные накопленные результаты после обработки всех изображений.

-----

## Результаты

В таблице представлены **финальные накопленные метрики** после обработки **3456 кадров** для всех четырех моделей.

| Модель | Обработано Кадров | Ср. Время (s) | TPR (Полнота) | FDR | True Positives (TP) | False Positives (FP) | False Negatives (FN) |
| :--- | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| **SSD MobileNet V3** | 3456 | **0.115** | **0.813** | 0.023 | 15711 | 366 | 3613 |
| **YOLOv4tiny** | 3456 | **0.045** | 0.803 | 0.049 | 15519 | 806 | 3805 |
| **yolov4** | 3456 | 0.389 | 0.787 | 0.033 | 15205 | 515 | 4119 |
| **Faster R-CNN** | 3456 | 0.242 | 0.703 | **0.066** | 13588 | 960 | 5736 |

### Анализ

  * **Лучшая Производительность (TPR):** Модель **SSD MobileNet V3** показывает самый высокий True Positive Rate (0.813), что означает, что она обнаружила наибольший процент фактических транспортных средств.
  * **Лучшая Скорость:** Модель **YOLOv4tiny** является самой быстрой со средним временем обработки **0.045s** на кадр, что делает ее идеальной для приложений реального времени, где важна скорость.
  * **Лучшая Точность (FDR):** Модель **SSD MobileNet V3** также демонстрирует самый низкий False Discovery Rate (0.023), что указывает на наименьшее количество ложных обнаружений.

-----

## Запуск приложения

Для запуска приложения необходимо указать пути к папкам с изображениями и файлу аннотаций, а также выбрать модель.

```bash
python main.py --images <путь_к_изображениям> --annotations <путь_к_аннотациям> --model <тип_модели> [опции]
```
Например:
```bash
python main.py --images imgs_MOV03478 --annotations mov03478.txt --model yolov4tiny --confidence 0.5 --show-ground-truth
```

### Доступные Аргументы:

| Аргумент | Описание | Обязательный | Выбор | По умолчанию |
| :--- | :--- | :---: | :--- | :---: |
| `--images` | Путь к директории с изображениями (файлы `.jpg`). | Да | - | - |
| `--annotations` | Путь к файлу аннотаций. | Да | - | - |
| `--model` | Тип модели для обнаружения. | Да | `yolov4`, `yolov4tiny`, `mobilenet`, `rcnn` | - |
| `--confidence` | Порог уверенности для обнаружения. | Нет | - | `0.5` |
| `--no-display` | Отключить отображение изображений и метрик. | Нет | - | Выкл. |
| `--show-ground-truth` | Отображать ограничивающие прямоугольники Ground Truth. | Нет | - | Выкл. |

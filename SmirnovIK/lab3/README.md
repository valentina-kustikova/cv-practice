# Практическая работа №3. Классификация изображений с использованием библиотеки OpenCV

## 1. Постановка задачи

Цель работы — реализовать и сравнить два подхода к классификации изображений:

1. **Классический метод «мешка визуальных слов» (Bag of Visual Words, BoVW)** с использованием локальных дескрипторов и SVM-классификатора.
    
2. **Нейросетевой подход** на основе предобученной сверточной нейронной сети (Transfer Learning).
    

Задачи:

- прочитать набор изображений
    
- выделить признаки методом SIFT
    
- построить визуальный словарь
    
- обучить модель SVM на BoVW-признаках
    
- обучить CNN или дообучить готовую
    
- провести сравнение точности методов
    
- представить результаты в виде таблицы
    
## 2. Описание алгоритма мешка визуальных слов

Метод «мешка визуальных слов» основан на аналогии с обработкой текста:  
вместо текстовых слов используются характерные локальные визуальные элементы изображения.

### Этапы метода:

|Этап|Описание|
|---|---|
|Выделение ключевых точек|Используются SIFT-детекторы для нахождения информативных точек изображения|
|Формирование дескрипторов|Для каждой точки вычисляется SIFT-вектор признаков|
|Построение словаря|Все дескрипторы кластеризуются методом k-means, центры кластеров — «визуальные слова»|
|Кодирование изображения|Каждый дескриптор заменяется ближайшим словом, строится гистограмма частот|
|Классификация|Полученные гистограммы используются для обучения SVM|

## 3. Ключевые элементы метода

### 3.1 Ключевые точки

Ключевые точки выбираются только в наиболее информативных местах изображения (углы, резкие изменения яркости).  
Это позволяет устойчиво сравнивать изображения при:

- изменении масштаба
    
- повороте
    
- освещении
    
- частичных перекрытиях объектов
    

> В работе использован детектор SIFT (Scale-Invariant Feature Transform).

### 3.2 Дескрипторы

Для каждой ключевой точки формируется вектор признаков, описывающий локальную структуру изображения.  
SIFT описывает:

- направление градиентов
    
- локальную структуру
    
- ориентацию
    

> SIFT даёт 128-мерный вектор.

### 3.3 Формирование словаря (кластеризация)

Собираются дескрипторы всех изображений и применяется k-means.  
Центры кластеров = _визуальные слова_.

Количество слов (k) задаётся заранее, обычно 100–1000. 

### 3.4 Построение гистограммы визуальных слов

Для каждого изображения:

- каждый локальный дескриптор привязывается к ближайшему слову в словаре
    
- строится гистограмма частот
    

Получаем вектор фиксированной длины k, который описывает изображение.

## 4. Классификация

На гистограммах обучается классический ML-классификатор.

> В реализованной программе выбран SVM (support vector machine)

## 5. Преимущества и недостатки метода BoVW
Плюсы
- Инвариантность к масштабу, повороту
- Классический ML — не требует GPU
- Хорошая интерпретируемость
- Работает при малых датасетах

Минусы
- Не учитывает структуру сцены - теряются пространственные связи
- Нужно вручную выбирать дескриптор (SIFT / ORB и др.)
- Не столь точен как CNN

## 6. Описание нейронной сети

В работе используется Transfer Learning:  
предобученная модель (VGG16) на ImageNet адаптируется под текущий набор данных.

### Этапы нейросетевого подхода:

- Загрузка предобученной CNN
- Заморозка базовых слоёв
- Замена выходного слоя
- Дообучение
- Оценка качества

### Преимущества CNN:

- автоматически извлекают признаки, в отличие от SIFT
- более высокое качество распознавания
- используют пространственную структуру изображения
    
## 7. Реализация программы

### Использованные библиотеки:

- OpenCV (SIFT, k-means, SVM)
    
- NumPy
    
- scikit-learn
    
- TensorFlow / Keras (нейронная сеть)
    

## 8. Результаты

### Точность классификации

|Метод|Точность|
|---|---|
|Bag of Visual Words + SVM|**88%**|
|Transfer Learning (CNN)|**95%**|

## 9. Выводы

В результате выполнения работы:

- Реализован метод мешка визуальных слов для классификации изображений
    
- Реализован и обучен нейросетевой классификатор с Transfer Learning
    
- Проведено сравнение методов
    

### Основные выводы:

- BoVW хорошо работает на небольших выборках и не требует мощного оборудования
    
- CNN обеспечивает более высокую точность
    
- При наличии ограниченных данных эффективна стратегия дообучения (Fine-Tuning)

# Практическая работа №2. Детектирование объектов на изображениях с использованием библиотеки OpenCV
### 1. Постановка задачи

Цель работы — разработка программной системы для детектирования объектов на последовательности изображений/видео, используя библиотеку OpenCV и встроенный модуль DNN.

Требуется реализовать поддержку нескольких архитектур нейронных сетей, а именно:

- YOLOv8
    
- SSD MobileNet
    
- NanoDet
    

Для каждой модели необходимо:

- выполнить загрузку модели и конфигурации
    
- реализовать методы предобработки входного изображения
    
- реализовать постобработку детекций (NMS, выбор класса, масштабирование координат)
    
- вывести результаты детекции на видео: рамка, класс, уверенность
    
- рассчитать показатели качества:
    
    - **TPR (True Positive Rate)**
        
    - **FDR (False Detection Rate)**
        

Система должна поддерживать интерактивный просмотр кадров и оценивать качество для каждого кадра отдельно, основываясь на перекрытии (IoU) предсказанной рамки и размеченной (ground truth).
### 2. Описание алгоритмов

### 2.1. Предобработка изображений

| Модель        | Предобработка                                                                                        |
| ------------- | ---------------------------------------------------------------------------------------------------- |
| YOLOv8        | масштабирование до 640×640, нормализация в диапазон [0,1]                                            |
| MobileNet SSD | масштабирование до 600×600                                              |
| NanoDet       | масштабирование до 416×416, нормализация, усреднение по каналам со средними: (103.53,116.28,123.675) |
Общее преобразование пикселей:

$$
x' = \frac{x - \mu}{\sigma}
$$
$\mu$ - среднее значение, $\sigma$ - стандартное отклонение
### 2.2. Постобработка

Основные шаги:

1. Прямой проход сети (`forward`)
    
2. Выбор наилучшего класса для каждой рамки (`argmax`)
  $$\hat{c} = \arg\max_k p_k$$
    
3. Применение порога confidence
$$p_{\hat{c}} \ge \tau_{conf}$$
    
4. NMS (Non-Maximum Suppression) для удаления пересекающихся рамок
    
5. Масштабирование координат на оригинальное изображение


### 2.3.Постобработка результатов YOLO — описание алгоритма

После того как нейронная сеть выдаёт массив предсказаний, выполняются следующие шаги:

##### 2.3.1. Получение набора гипотез

Модель возвращает список гипотез, где каждая гипотеза содержит:

- координаты потенциального объекта (в формате «центр + размер»)
$$(x_c, y_c, w, h)$$
- набор вероятностей того, что объект принадлежит каждому возможному классу

##### 2.3.2. Определение наиболее вероятного класса для каждой гипотезы

Для каждой гипотезы:

- выбирается класс с наибольшей вероятностью
    $$\hat{c} = \arg\max_c p_c$$
- фиксируется максимальное значение вероятности
$$p = \max_c p_c$$
##### 2.3.3. Отбор только достоверных предсказаний

Проверяется уверенность модели:

- если вероятность класса ниже заданного порога, гипотеза отвергается
    
- если выше — гипотеза сохраняется

Таким образом исключается шум и случайные слабые предсказания.


##### 2.3.4. Преобразование координат

YOLO предсказывает координаты в формате: центр объекта + ширина и высота рамки: $$(x_c, y_c, w, h)$$
Чтобы получить координаты рамки, выполняется преобразование к формату: левый верхний угол + ширина и высота
$$x_1 = x_c - \frac{w}{2},\qquad y_1 = y_c - \frac{h}{2}$$

$$x_2 = x_c + \frac{w}{2},\qquad y_2 = y_c + \frac{h}{2}$$

##### 2.3.5. Удаление дублирующихся рамок (Non-Max Suppression)

У разных гипотез могут быть похожие координаты, то есть модель может найти один и тот же объект несколько раз.

Для устранения дублей:

- сравниваются пары рамок
    
- если две рамки сильно перекрываются, оставляется только та, у которой вероятность выше

Для этого используется метрика IoU:

$$IoU(A,B)=\frac{|A\cap B|}{|A|+|B|-|A\cap B|}$$

Удаляем рамку ($A_j$), если:

$$IoU(A_i, A_j) > \tau_{nms}$$

##### 2.3.6. Масштабирование рамок к размеру исходного изображения

Объект детектировался на уменьшенной копии изображения (например, 640×640).  
Поэтому размеры и координаты рамок пересчитываются: из размеров входа сети к размерам исходного изображения ($W$ - ширина исходного изображения, $H$ - высота исходного изображения)
$$x_{pix} = x \cdot W,\qquad y_{pix} = y \cdot H$$
Это гарантирует, что рамки лягут на оригинальный кадр корректно.

##### 2.3.7. Формирование результата

Для каждого оставшегося объекта возвращается:

- конечная рамка на изображении
    
- уверенность модели
    
- класс объекта

### 2.4. Постобработка MobileNet SSD — описание алгоритма
После выполнения прямого прохода через сеть детекции, модель возвращает список найденных объектов. Каждый из них содержит:
$$[x_{min}, y_{min}, x_{max}, y_{max},~ conf,~ class]$$
- координаты ограничивающей рамки
    
- уверенность модели, что объект присутствует
    
- предполагаемый класс объекта
    
Далее выполняются следующие шаги:

##### 2.4.1. Отбор детекций по порогу уверенности

Для каждой найденной гипотезы проверяется значение уверенности:

- если уверенность модели меньше заданного порога, детекция отбрасывается
    
- если выше порога — оставляется


##### 2.4.2 . Подавление повторяющихся рамок (Non-Maximum Suppression)

Так как модель может предсказать несколько близких рамок для одного и того же объекта, применяется **NMS**:

- каждая рамка сравнивается с другими
    
- если две рамки сильно перекрываются
    
- оставляется только рамка с большей уверенностью
    
Для этого используется метрика IoU:

$$IoU(A,B)=\frac{|A\cap B|}{|A|+|B|-|A\cap B|}$$

Удаляем рамку ($A_j$), если:

$$IoU(A_i, A_j) > \tau_{nms}$$

Таким образом удаляются дублирующие детекции.

##### 2.4.3. Приведение координат

Координаты рамок уже заданы в формате: левый верхний угол + ширина + высота
и относятся непосредственно к исходному изображению (масштабирование не требуется, так как модель возвращает координаты в глобальной системе изображения).

##### 2.4.4. Формирование результата

Для каждого итогового объекта сохраняется:

- позиция рамки на изображении
    
- вероятность (уверенность модели)
    
- финальный класс объекта

### 2.5. Постобработка NanoDet — описание алгоритма

Модель NanoDet предсказывает:

- вероятность объектов разных классов
    
- расстояния от каждого пикселя сетки к границам объекта (регрессию рамки)
    

Причём расстояния предсказываются как дискретное распределение, и затем восстанавливаются через soft-argmax.

##### 2.5.1. Разделение выходов по уровням feature map (head outputs)

Модель формирует предсказания на нескольких масштабах изображения  
(например, для мастштабов в 8, 16, 32, 64 раз меньше).

Для каждого масштаба:

- создаётся регулярная сетка ячеек
    
- каждая ячейка может "ответить", что там находится объект
    

На каждом уровне выход разделяется на:

- вероятности классов
    
- параметры рамок, закодированные как 4 набора вероятностей расстояний
    

##### 2.5.2. Восстановление рамок из дискретной регрессии (soft-argmax decoding)

NanoDet не предсказывает координаты рамки напрямую. Для каждого направления (лево/верх/право/низ) выдаётся набор логитов, которые представляют распределение вероятностей расстояния от точки-якоря.
Модель предсказывает логиты:

$$z_i∈R^8$$

Алгоритм декодирования:

- применить экспоненту для получения нелинейной вероятностной шкалы
    
- умножить вероятности на индекс позиции — это даёт ожидание распределения (soft-argmax)
$$e_i=exp⁡(z_i)$$
$$P_i=\frac {e_i}{\sum_{j=0}^{K−1}e_j},~~~~~~K=8$$
$$d = \sum_{i=0}^{K-1} P_i \cdot i$$
- перемножить результат на шаг сетки $pitch$
    $$d := d \cdot pitch$$
    Получили предсказанный сдвиг $d$ от центра ячейки
- вычислить координаты рамки, используя смещение $d$
    $$x_1 = x_c - d,\qquad y_1 = y_c - d$$
    $$x_2 = x_c + d,\qquad y_2 = y_c + d$$
- результат ограничить областями кадра
    
$$x_1​=max(x_1​,0) ~~~~~ y_1=max⁡(y_1,0)~~~~~ x_2=min⁡(x_2,1)~~~~~y_2=min⁡(y_2,1)$$
То есть восстанавливается наиболее вероятная рамка вокруг центра ячейки.
##### 2.5.3. Объединение результатов со всех уровней

После распаковки предсказаний с каждого масштабного уровня:

- объединяются все рамки
    
- объединяются все вероятности классов
    

Таким образом модель учитывает объекты разного размера.


##### 2.5.4. Выбор класса и фильтрация по порогу уверенности

Для каждой рамки:

- определяется класс с максимальной вероятностью
    
- извлекается его confidence-оценка
    
- рамка отбрасывается, если уверенность ниже минимального порога
    

Это удаляет слабые и случайные детекции.

##### 2.5.5. Преобразование координат к пиксельным

Модель работает в нормализованных координатах $[0,1]$, поэтому:

- координаты домножаются на размеры исходного изображения
    
- получаются реальные пиксельные координаты на кадре ($W$ - ширина исходного изображения, $H$ - высота исходного изображения)
    $$x_{pix} = x \cdot W,\qquad y_{pix} = y \cdot H$$
##### 2.5.6. Подавление пересекающихся рамок (NMS)

Несколько соседних ячеек могут предсказать один и тот же объект.

Поэтому выполняется **Non-Maximum Suppression**:

- рамки сравниваются попарно
    
- если две рамки сильно пересекаются, остаётся только та, у которой выше уверенность
    
Для этого используется метрика IoU:

$$IoU(A,B)=\frac{|A\cap B|}{|A|+|B|-|A\cap B|}$$

Удаляем рамку ($A_j$), если:

$$IoU(A_i, A_j) > \tau_{nms}$$

##### 2.5.7. Формирование итогового набора объектов

Для каждой оставшейся рамки сохраняются:

- координаты (левый верхний угол, ширина, высота)
    
- уверенность модели
    
- класс объекта

### 3. Реализация программы

Разработана иерархия классов:

- `BaseDetector`
    
- `YOLOv8Detector`
    
- `MobileNetDetector`
    
- `NanoDetDetector`
    

Каждая модель реализует:

- `preprocess()`
    
- `postprocess()`
    
- `detect()`
    

Для каждого кадра выполняется:

- детекция объектов
    
- сравнение с ground truth (IoU ≥ 0.5 считается совпадением)
    
- вычисление TPR и FDR
    
- вывод рамки, класса, уверенности и метрик на изображение

### 4. Методика оценки качества

Для оценки качества работы детекторов в задаче обнаружения объектов применяются показатели **TPR (True Positive Rate)** и **FDR (False Discovery Rate)**.  
Метрики вычисляются на каждом кадре на основе пересечения предсказанных рамок с разметкой (Ground Truth) по критерию **IoU (Intersection over Union)**.

$$
TPR = \frac{TP}{TP+FN}, ~~~~~~~FDR = \frac{FP}{TP+FP}
$$

$$
IoU=\frac{Area(Union)}{Area(Intersection)}
$$

Где:

- `Intersection` — площадь пересечения предсказанной рамки и истинной (разметки)
    
- `Union` — сумма площадей двух рамок минус площадь пересечения
    

IoU используется для проверки, считается ли найденная рамка корректным попаданием.  
Если IoU ≥ порог (например, 0.5) — рамка считается совпавшей.

###### True Positive (TP)
Корректная детекция:

- класс предсказан правильно
    
- рамка достаточно точно совпадает с разметкой ($IoU \geq threshold$)
    
###### False Positive (FP)

Срабатывание, которого быть не должно, то есть модель _нашла несуществующий объект_, или:
- модель обнаружила объект, но класс неправильный
    
- рамка не совпадает с истинным объектом ($IoU < threshold$)
    
###### False Negative (FN)

Модель пропустила объект, т.е. объект есть в разметке, но модель ничего не нашла или нашла рамку, которая не соответствует критериям верного попадания.​

Высокий TPR означает, что модель реже пропускает объекты, а низкий FDR означает, что модель редко ошибается.

### 5. Таблица результатов

| Модель        | Средняя точность (TPR) | Средняя ошибка (FDR) | Особенности                                                     |
| ------------- | ---------------------- | -------------------- | --------------------------------------------------------------- |
| YOLOv8-n      | 0.639                  | 0.368                | часто путает объекты или не находит их                          |
| MobileNet SSD | 0.832                  | 0.131                | модель надёжная по детекциям и редко ошибается                  |
| NanoDet       | 0.904                  | 0.271                | находит больше объектов, но иногда даёт избыточные предсказания |

### 6. Выводы

В ходе выполнения работы:

- Реализована система детекции объектов на видео в реальном времени
    
- Поддержаны три современных архитектуры нейронных сетей
    
- Реализованы общие и модель-специфичные алгоритмы пред- и пост-обработки
    
- Выполнена оценка качества с использованием метрик IoU, TPR, FDR
    
- Построена модульная, расширяемая структура программы
    
- Выполнена визуализация результатов и корректная обработка данных разметки
    


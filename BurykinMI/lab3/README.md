# Практическая работа №3. Классификация изображений с использованием библиотеки OpenCV

## Цель работы

Разработать приложение для классификации изображений известных достопримечательностей Нижнего Новгорода (Нижегородский
Кремль, Архангельский собор, Дворец труда). Приложение реализует алгоритм "мешок визуальных слов" (Bag of Words, BoW) с
использованием различных детекторов и дескрипторов признаков. Набор данных загружается из директорий `ExtDataset` (
фотографии из интернета) и `NNSUDataset` (фотографии студентов ИИТММ). Разбиение на тренировочную и тестовую выборки
предоставляется в файле `train.txt`. Нейросетевой подход предусмотрен, но не реализован (TODO).

Данные доступны по [ссылке на набор данных](https://cloud.unn.ru/s/2KsWFmaxzZf9mF5) (включая файл с источниками для
`ExtDataset`). Разбиение на выборки — по [ссылке](https://cloud.unn.ru/s/ynKNZH9TxiwXqEb). Дополнительные изображения не
добавлялись, использовался исходный набор.

---

## Структура проекта

```
BurykinMI/
└── lab3/
    ├── abstract.py                        # Абстрактные базовые классы (FeatureExtractor, ClassificationStrategy)
    ├── feature_extractor.py               # Реализация экстракторов признаков (SIFT, ORB, AKAZE)
    ├── bow_strategy.py                    # Стратегия Bag of Words + SVM
    ├── nn_strategy.py                     # Заглушка для нейросетевой стратегии (TODO)
    ├── dataset_loader.py                  # Загрузчик и препроцессор датасета
    ├── evaluator.py                       # Оценка качества модели (метрики, отчеты)
    ├── classifier.py                      # Главный модуль: фасад, фабрика, main()
    ├── visualizer.py                      # Визуализация ключевых точек и совпадений
    ├── visualize_keypoints.py             # CLI-скрипт для визуализации
    ├── README.md                          # Описание работы
    ├── data/
    │   ├── train.txt                      # Файл разбиения на тренировочную и тестовую выборки
    │   ├── ExtDataset/                    # Фотографии из интернета
    │   │   ├── 01_NizhnyNovgorodKremlin/
    │   │   ├── 04_ArkhangelskCathedral/
    │   │   ├── 08_PalaceOfLabor/
    │   │   └── references.csv             # Ссылки на источники
    │   └── NNSUDataset/                   # Фотографии студентов ИИТММ
    │       ├── 01_NizhnyNovgorodKremlin/
    │       ├── 04_ArkhangelskCathedral/
    │       └── 08_PalaceOfLabor/
    ├── models/
    │   └── bow/
    │       ├── akaze_clusters300.pkl          # Модель для AKAZE (300 кластеров)
    │       ├── orb_clusters300.pkl            # Модель для ORB (300 кластеров)
    │       ├── sift_clusters300.pkl           # Модель для SIFT (300 кластеров)
    │       ├── akaze_clusters300_results.json # Результаты тестирования для AKAZE
    │       ├── orb_clusters300_results.json   # Результаты тестирования для ORB
    │       └── sift_clusters300_results.json  # Результаты тестирования для SIFT
    └── visualizations/                    # Результаты визуализации ключевых точек
```

---

## Архитектура приложения

Приложение построено с использованием ООП-принципов и паттернов проектирования:

### Паттерны проектирования

1. **Strategy (Стратегия)**: Различные алгоритмы классификации (BoW, Neural) реализуют общий интерфейс
   `ClassificationStrategy`, что позволяет легко переключаться между ними.

2. **Factory (Фабрика)**: `StrategyFactory` создает конкретные стратегии на основе параметров, инкапсулируя логику
   создания объектов.

3. **Facade (Фасад)**: `LandmarkClassifier` предоставляет упрощенный интерфейс для работы со стратегиями, скрывая
   сложность внутренней реализации.

### Основные модули

- **abstract.py**: Абстрактные базовые классы, определяющие контракты
- **feature_extractor.py**: Извлечение признаков через детекторы OpenCV
- **bow_strategy.py**: Реализация алгоритма Bag of Words
- **dataset_loader.py**: Загрузка и разделение данных
- **evaluator.py**: Вычисление метрик качества
- **classifier.py**: Точка входа, координация всех компонентов
- **visualizer.py**: Визуализация работы детекторов признаков
- **visualize_keypoints.py**: CLI для визуализации

---

## Описание алгоритма Bag of Words

### Этапы работы:

1. **Извлечение признаков**: Из каждого тренировочного изображения извлекаются локальные дескрипторы с помощью
   детекторов (SIFT, ORB, AKAZE).

2. **Построение словаря**: Все дескрипторы кластеризуются методом K-Means (MiniBatchKMeans) на заданное количество
   кластеров (по умолчанию 300). Центры кластеров становятся "визуальными словами".

3. **Получение BoW-представления**: Для каждого изображения:
    - Извлекаются дескрипторы
    - Каждый дескриптор относится к ближайшему визуальному слову
    - Строится нормализованная гистограмма встречаемости слов

4. **Обучение классификатора**: SVM с RBF-ядром (C=10) обучается на BoW-представлениях изображений.

5. **Предсказание**: Для нового изображения строится BoW-представление и подается на вход SVM.

### Исследованные детекторы

- **SIFT** (Scale-Invariant Feature Transform): Инвариантен к масштабу и вращению, дает float-дескрипторы высокого
  качества
- **ORB** (Oriented FAST and Rotated BRIEF): Быстрый бинарный дескриптор, открытая альтернатива SIFT
- **AKAZE** (Accelerated-KAZE): Нелинейные масштабные пространства, хороший баланс скорости и качества

---

## Результаты экспериментов

Все модели обучены на одном разбиении данных с 300 кластерами. Тестирование проведено на 88 изображениях.

### Описание метрик качества

Для оценки качества классификации используются следующие метрики:

- **Accuracy (Точность)** - доля правильно классифицированных изображений от общего числа. Показывает общую
  эффективность модели.

- **Precision (Прецизионность)** - доля истинно положительных предсказаний среди всех положительных предсказаний модели.
  Отвечает на вопрос: "Из всех изображений, которые модель отнесла к классу X, сколько действительно принадлежат этому
  классу?"

- **Recall (Полнота)** - доля истинно положительных предсказаний среди всех реальных положительных примеров. Отвечает на
  вопрос: "Из всех изображений класса X, сколько модель смогла правильно распознать?"

- **F1-score** - гармоническое среднее между Precision и Recall. Балансирует между точностью и полнотой, особенно
  полезен при несбалансированных классах.

- **Macro average** - среднее арифметическое метрик по всем классам (каждый класс имеет равный вес).

- **Weighted average** - взвешенное среднее метрик, где вес каждого класса пропорционален количеству его примеров в
  тестовой выборке.

### Сравнительная таблица

| Детектор | Accuracy | Precision (macro) | Recall (macro) | F1-score (macro) |
|----------|----------|-------------------|----------------|------------------|
| SIFT     | 0.9545   | 0.9604            | 0.9333         | 0.9423           |
| AKAZE    | 0.8977   | 0.9009            | 0.8685         | 0.8803           |
| ORB      | 0.7955   | 0.8005            | 0.7502         | 0.7721           |

### Детальные результаты по классам

**SIFT (лучший результат):**

- cathedral: Precision=1.00, Recall=0.80, F1=0.89
- kremlin: Precision=0.98, Recall=1.00, F1=0.99
- palace: Precision=0.91, Recall=1.00, F1=0.95

**AKAZE:**

- cathedral: Precision=0.88, Recall=0.70, F1=0.78
- kremlin: Precision=0.86, Recall=0.97, F1=0.92
- palace: Precision=0.96, Recall=0.93, F1=0.95

**ORB (самый быстрый, но менее точный):**

- cathedral: Precision=0.83, Recall=0.50, F1=0.63
- kremlin: Precision=0.82, Recall=0.92, F1=0.87
- palace: Precision=0.75, Recall=0.83, F1=0.79

### Выводы

1. **SIFT** показывает наилучшее качество классификации (95.45% accuracy)
2. **AKAZE** — хороший баланс между скоростью и точностью (89.77%)
3. **ORB** — самый быстрый, но менее точный (79.55%)
4. Класс "cathedral" оказался наиболее сложным для всех детекторов (низкий Recall говорит о том, что многие изображения
   соборов не распознаются)
5. Класс "kremlin" распознается лучше всего благодаря характерным архитектурным особенностям
6. SVM с RBF-ядром хорошо справляется с нелинейной классификацией BoW-представлений

---

## Запуск программы

### Обучение и тестирование классификатора

Основной скрипт `classifier.py` запускается с параметрами командной строки:

```bash
python classifier.py --data_dir <путь_к_данным> [опции]
```

#### Примеры использования:

**Обучение и тестирование (BoW, SIFT, 300 кластеров):**

```bash
python classifier.py --data_dir data/ --mode train_test --algorithm bow --detector sift --n_clusters 300
```

**Только тестирование (загрузка модели):**

```bash
python classifier.py --data_dir data/ --mode test --algorithm bow --detector sift --n_clusters 300
```

**Другие детекторы:**

```bash
# ORB
python classifier.py --data_dir data/ --mode train_test --algorithm bow --detector orb --n_clusters 300

# AKAZE
python classifier.py --data_dir data/ --mode train_test --algorithm bow --detector akaze --n_clusters 300
```

**Изменение количества кластеров:**

```bash
python classifier.py --data_dir data/ --mode train_test --algorithm bow --detector sift --n_clusters 500
```

#### Параметры командной строки:

- `--data_dir`: Путь до директории с данными (обязательный)
- `--split_file`: Файл разбиения (по умолчанию `data_dir/train.txt`)
- `--mode`: Режим работы (`train`, `test`, `train_test`)
- `--algorithm`: Алгоритм классификации (`bow`, `neural`)
- `--detector`: Тип детектора признаков (`sift`, `orb`, `akaze`)
- `--n_clusters`: Количество кластеров для BoW (по умолчанию 300)
- `--models_dir`: Директория для сохранения моделей (по умолчанию `models`)

### Визуализация ключевых точек

Скрипт `visualize_keypoints.py` позволяет визуализировать работу детекторов:

```bash
python visualize_keypoints.py --image <путь_к_изображению> [опции]
```

#### Примеры использования:

**Визуализация ключевых точек для одного изображения:**

```bash
python visualize_keypoints.py --image data/ExtDataset/01_NizhnyNovgorodKremlin/ivanovskaya.png --detector sift
```

**Ограничение количества отображаемых точек (топ-100 по значимости):**

```bash
python visualize_keypoints.py --image data/ExtDataset/01_NizhnyNovgorodKremlin/ivanovskaya.png --detector sift --max_keypoints 100
```

**Сравнение всех трех детекторов на одной картинке:**

```bash
python visualize_keypoints.py --image data/ExtDataset/01_NizhnyNovgorodKremlin/ivanovskaya.png --mode compare
```

**Визуализация совпадающих точек между двумя изображениями:**

```bash
python visualize_keypoints.py \
  --image data/ExtDataset/01_NizhnyNovgorodKremlin/ivanovskaya.png \
  --image2 data/ExtDataset/01_NizhnyNovgorodKremlin/porohovaya.png \
  --mode matches \
  --detector sift \
  --max_matches 50
```

**Сохранение без показа окна:**

```bash
python visualize_keypoints.py --image data/ExtDataset/01_NizhnyNovgorodKremlin/ivanovskaya.png --detector sift --no_show
```

#### Параметры визуализации:

- `--image`: Путь к изображению (обязательный)
- `--detector`: Тип детектора (`sift`, `orb`, `akaze`)
- `--mode`: Режим визуализации:
    - `single`: визуализация одного детектора
    - `compare`: сравнение всех трех детекторов
    - `matches`: совпадения между двумя изображениями
- `--image2`: Второе изображение (для режима `matches`)
- `--max_keypoints`: Максимальное количество ключевых точек
- `--max_matches`: Максимальное количество совпадений (для `matches`)
- `--output_dir`: Директория для сохранения (по умолчанию `visualizations`)
- `--no_show`: Не показывать окно с результатом

#### Что показывает визуализация:

- **Зеленые круги**: ключевые точки
- **Размер кругов**: сила отклика детектора (чем больше, тем значимее точка)
- **Направление внутри круга**: ориентация ключевой точки
- **Текст**: название детектора и количество найденных точек
- **Линии** (в режиме matches): связи между совпадающими точками на двух изображениях

Все результаты автоматически сохраняются в директорию `visualizations/`.

---

## Требования к данным

- Директория `--data_dir` должна содержать `ExtDataset` и `NNSUDataset` с подпапками классов:
    - `01_NizhnyNovgorodKremlin` → класс `kremlin`
    - `04_ArkhangelskCathedral` → класс `cathedral`
    - `08_PalaceOfLabor` → класс `palace`
- Файл разбиения (`train.txt`) — список относительных путей к тренировочным изображениям
- Поддерживаемые форматы: JPG, JPEG, PNG, BMP
- Если добавляются дополнительные фото, обновите `train.txt` и создайте `references.csv` для источников

---

## Используемые библиотеки

- **OpenCV (cv2)**: Детекторы/дескрипторы (SIFT, ORB, AKAZE), чтение и обработка изображений, визуализация
- **NumPy**: Операции с массивами, гистограммы, нормализация
- **Scikit-learn**:
    - Кластеризация: `MiniBatchKMeans`
    - Классификация: `SVC` (Support Vector Classifier)
    - Метрики: `accuracy_score`, `classification_report`, `confusion_matrix`
- **Matplotlib**: Отображение результатов визуализации
- **Pickle**: Сериализация и сохранение моделей
- **JSON**: Сохранение результатов оценки
- **OS, Argparse**: Работа с файловой системой и парсинг аргументов

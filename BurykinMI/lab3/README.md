# Практическая работа №3. Классификация изображений с использованием библиотеки OpenCV

## Цель работы

Разработать приложение для классификации изображений известных достопримечательностей Нижнего Новгорода (Нижегородский
Кремль, Архангельский собор, Дворец труда). Приложение реализует два подхода:
1. Классический компьютерное зрение: "мешок визуальных слов" (Bag of Words, BoW).
2. Глубокое обучение: Сверточная нейронная сеть (ResNet18) с использованием переноса обучения (Transfer Learning).

Данные доступны по [ссылке на набор данных](https://cloud.unn.ru/s/2KsWFmaxzZf9mF5) (включая файл с источниками для
`ExtDataset`). Разбиение на выборки — по [ссылке](https://cloud.unn.ru/s/ynKNZH9TxiwXqEb). Дополнительные изображения не
добавлялись, использовался исходный набор.

---

## Структура проекта

```
BurykinMI/
└── lab3/
    ├── abstract.py                        # Абстрактные базовые классы (FeatureExtractor, ClassificationStrategy)
    ├── feature_extractor.py               # Реализация экстракторов признаков (SIFT, ORB, AKAZE)
    ├── bow_strategy.py                    # Стратегия Bag of Words + SVM
    ├── nn_strategy.py                     # Стратегия Нейронной сети (PyTorch, ResNet)
    ├── dataset_loader.py                  # Загрузчик и препроцессор датасета
    ├── evaluator.py                       # Оценка качества модели (метрики, отчеты)
    ├── classifier.py                      # Главный модуль: фасад, фабрика, main()
    ├── visualizer.py                      # Визуализация ключевых точек и совпадений
    ├── visualize_keypoints.py             # CLI-скрипт для визуализации
    ├── README.md                          # Описание работы
    ├── data/
    │   ├── train.txt                      # Файл разбиения на тренировочную и тестовую выборки
    │   ├── ExtDataset/                    # Фотографии из интернета
    │   │   ├── 01_NizhnyNovgorodKremlin/
    │   │   ├── 04_ArkhangelskCathedral/
    │   │   ├── 08_PalaceOfLabor/
    │   │   └── references.csv             # Ссылки на источники
    │   └── NNSUDataset/                   # Фотографии студентов ИИТММ
    │       ├── 01_NizhnyNovgorodKremlin/
    │       ├── 04_ArkhangelskCathedral/
    │       └── 08_PalaceOfLabor/
    ├── models/
    │   └── bow/
    │       ├── akaze_clusters300.pkl          # Модель для AKAZE (300 кластеров)
    │       ├── orb_clusters300.pkl            # Модель для ORB (300 кластеров)
    │       ├── sift_clusters300.pkl           # Модель для SIFT (300 кластеров)
    │       ├── akaze_clusters300_results.json # Результаты тестирования для AKAZE
    │       ├── orb_clusters300_results.json   # Результаты тестирования для ORB
    │       └── sift_clusters300_results.json  # Результаты тестирования для SIFT
    └── visualizations/                    # Результаты визуализации ключевых точек
```

---

## Архитектура приложения

Приложение построено с использованием ООП-принципов и паттернов проектирования:

### Паттерны проектирования

1. **Strategy (Стратегия)**: Различные алгоритмы классификации (BoW, Neural) реализуют общий интерфейс
   `ClassificationStrategy`, что позволяет легко переключаться между ними.

2. **Factory (Фабрика)**: `StrategyFactory` создает конкретные стратегии на основе параметров, инкапсулируя логику
   создания объектов.

3. **Facade (Фасад)**: `LandmarkClassifier` предоставляет упрощенный интерфейс для работы со стратегиями, скрывая
   сложность внутренней реализации.

### Основные модули

- **abstract.py**: Абстрактные базовые классы, определяющие контракты
- **feature_extractor.py**: Извлечение признаков через детекторы OpenCV
- **bow_strategy.py**: Реализация алгоритма Bag of Words
- **dataset_loader.py**: Загрузка и разделение данных
- **evaluator.py**: Вычисление метрик качества
- **classifier.py**: Точка входа, координация всех компонентов
- **visualizer.py**: Визуализация работы детекторов признаков
- **visualize_keypoints.py**: CLI для визуализации

---

## Описание алгоритмов

### 1. Мешок визуальных слов (Bag of Words)

#### Этапы работы:

1. **Извлечение признаков**: Из каждого тренировочного изображения извлекаются локальные дескрипторы с помощью
   детекторов (SIFT, ORB, AKAZE).

2. **Построение словаря**: Все дескрипторы кластеризуются методом K-Means (MiniBatchKMeans) на заданное количество
   кластеров (по умолчанию 300). Центры кластеров становятся "визуальными словами".

3. **Получение BoW-представления**: Для каждого изображения:
    - Извлекаются дескрипторы
    - Каждый дескриптор относится к ближайшему визуальному слову
    - Строится нормализованная гистограмма встречаемости слов

4. **Обучение классификатора**: SVM с RBF-ядром (C=10) обучается на BoW-представлениях изображений.

5. **Предсказание**: Для нового изображения строится BoW-представление и подается на вход SVM.

#### Исследованные детекторы

- **SIFT** (Scale-Invariant Feature Transform): Инвариантен к масштабу и вращению, дает float-дескрипторы высокого
  качества
- **ORB** (Oriented FAST and Rotated BRIEF): Быстрый бинарный дескриптор, открытая альтернатива SIFT
- **AKAZE** (Accelerated-KAZE): Нелинейные масштабные пространства, хороший баланс скорости и качества

### 2. Нейросетевой подход (Transfer Learning)
Реализован в `nn_strategy.py`.
Используется модель **ResNet18**, предварительно обученная на наборе данных ImageNet (1.2 млн изображений, 1000 классов).

**Методика Transfer Learning:**
1. Загружаются веса обученной сети.
2. Основные слои сети "замораживаются" (`requires_grad=False`). Они работают как мощный экстрактор признаков, выделяя линии, текстуры и формы.
3. Последний полносвязный слой (Fully Connected) заменяется на новый, имеющий 3 выхода (по числу наших классов).
4. Обучается (fine-tuning) только этот последний слой.

**Преимущества:**
* Позволяет получить высокую точность на малом наборе данных (наши несколько сотен фото).
* Обучение происходит очень быстро (так как обучается всего один слой).

**Аугментация данных:**
Для улучшения обобщающей способности при обучении применяются случайные трансформации:
* `RandomCrop`: случайная обрезка.
* `RandomHorizontalFlip`: случайное отражение по горизонтали.
* Нормализация по статистике ImageNet.

---

## Результаты экспериментов

Все модели обучены на одном разбиении данных. Для алгоритма BoW использовалось 300 кластеров. Нейросеть (ResNet18) обучалась 10 эпох. Тестирование проведено на 88 изображениях.

### Описание метрик качества

Для оценки качества классификации используются следующие метрики:

- **Accuracy (Точность)** - доля правильно классифицированных изображений от общего числа. Показывает общую эффективность модели.
- **Precision (Прецизионность)** - доля истинно положительных предсказаний среди всех положительных предсказаний модели.
- **Recall (Полнота)** - доля истинно положительных предсказаний среди всех реальных положительных примеров.
- **F1-score** - гармоническое среднее между Precision и Recall. Балансирует между точностью и полнотой.
- **Macro average** - среднее арифметическое метрик по всем классам.

### Сравнительная таблица

| Алгоритм / Детектор   | Accuracy   | Precision (macro) | Recall (macro) | F1-score (macro) |
|-----------------------|------------|-------------------|----------------|------------------|
| **ResNet18 (Neural)** | **0.9886** | **0.9917**        | **0.9833**     | **0.9872**       |
| SIFT (BoW)            | 0.9545     | 0.9604            | 0.9333         | 0.9423           |
| AKAZE (BoW)           | 0.8977     | 0.9009            | 0.8685         | 0.8803           |
| ORB (BoW)             | 0.7955     | 0.8005            | 0.7502         | 0.7721           |

### Детальные результаты по классам

**ResNet18 (Transfer Learning) — лучший результат:**

- cathedral: Precision=1.00, Recall=0.95, F1=0.97 (1 ошибка: собор принят за кремль)
- kremlin: Precision=0.98, Recall=1.00, F1=0.99
- palace: Precision=1.00, Recall=1.00, F1=1.00 (Идеальное распознавание)

**SIFT:**

- cathedral: Precision=1.00, Recall=0.80, F1=0.89
- kremlin: Precision=0.98, Recall=1.00, F1=0.99
- palace: Precision=0.91, Recall=1.00, F1=0.95

**AKAZE:**

- cathedral: Precision=0.88, Recall=0.70, F1=0.78
- kremlin: Precision=0.86, Recall=0.97, F1=0.92
- palace: Precision=0.96, Recall=0.93, F1=0.95

**ORB (самый быстрый, но менее точный):**

- cathedral: Precision=0.83, Recall=0.50, F1=0.63
- kremlin: Precision=0.82, Recall=0.92, F1=0.87
- palace: Precision=0.75, Recall=0.83, F1=0.79

### Выводы

1. **ResNet18 (Нейросеть)** показала наивысшую точность (**98.86%**), допустив всего одну ошибку на всей тестовой выборке. Подход с переносом обучения (Transfer Learning) оказался наиболее эффективным для данной задачи.
2. **SIFT** является лучшим среди классических алгоритмов компьютерного зрения (95.45%), значительно опережая бинарные дескрипторы.
3. **ORB** показывает худший результат (79.55%), что ожидаемо для дескриптора, ориентированного на скорость работы в реальном времени, а не на высокую точность классификации сцен.

---

## Запуск программы

### Запуск нейронной сети

Обучение и тестирование (10 эпох):
```bash
python classifier.py --data_dir data/ --mode train_test --algorithm neural --epochs 10
```
Просто тестирование (если модель models/neural/resnet_model.pth уже существует):
```bash
python classifier.py --data_dir data/ --mode test --algorithm neural
```

### Запуск Bag of Words (BoW)

Основной скрипт `classifier.py` запускается с параметрами командной строки:

```bash
python classifier.py --data_dir <путь_к_данным> [опции]
```

#### Примеры использования:

**Обучение и тестирование (BoW, SIFT, 300 кластеров):**

```bash
python classifier.py --data_dir data/ --mode train_test --algorithm bow --detector sift --n_clusters 300
```

**Только тестирование (загрузка модели):**

```bash
python classifier.py --data_dir data/ --mode test --algorithm bow --detector sift --n_clusters 300
```

**Другие детекторы:**

```bash
# ORB
python classifier.py --data_dir data/ --mode train_test --algorithm bow --detector orb --n_clusters 300

# AKAZE
python classifier.py --data_dir data/ --mode train_test --algorithm bow --detector akaze --n_clusters 300
```

**Изменение количества кластеров:**

```bash
python classifier.py --data_dir data/ --mode train_test --algorithm bow --detector sift --n_clusters 500
```

#### Параметры командной строки:

- `--data_dir`: Путь до директории с данными (обязательный)
- `--split_file`: Файл разбиения (по умолчанию `data_dir/train.txt`)
- `--mode`: Режим работы (`train`, `test`, `train_test`)
- `--algorithm`: Алгоритм классификации (`bow`, `neural`)
- `--detector`: Тип детектора признаков (`sift`, `orb`, `akaze`)
- `--n_clusters`: Количество кластеров для BoW (по умолчанию 300)
- `--models_dir`: Директория для сохранения моделей (по умолчанию `models`)

### Визуализация ключевых точек

Скрипт `visualize_keypoints.py` позволяет визуализировать работу детекторов:

```bash
python visualize_keypoints.py --image <путь_к_изображению> [опции]
```

#### Примеры использования:

**Визуализация ключевых точек для одного изображения:**

```bash
python visualize_keypoints.py --image data/ExtDataset/01_NizhnyNovgorodKremlin/ivanovskaya.png --detector sift
```

**Ограничение количества отображаемых точек (топ-100 по значимости):**

```bash
python visualize_keypoints.py --image data/ExtDataset/01_NizhnyNovgorodKremlin/ivanovskaya.png --detector sift --max_keypoints 100
```

**Сравнение всех трех детекторов на одной картинке:**

```bash
python visualize_keypoints.py --image data/ExtDataset/01_NizhnyNovgorodKremlin/ivanovskaya.png --mode compare
```

**Визуализация совпадающих точек между двумя изображениями:**

```bash
python visualize_keypoints.py \
  --image data/ExtDataset/01_NizhnyNovgorodKremlin/ivanovskaya.png \
  --image2 data/ExtDataset/01_NizhnyNovgorodKremlin/porohovaya.png \
  --mode matches \
  --detector sift \
  --max_matches 50
```

**Сохранение без показа окна:**

```bash
python visualize_keypoints.py --image data/ExtDataset/01_NizhnyNovgorodKremlin/ivanovskaya.png --detector sift --no_show
```

#### Параметры визуализации:

- `--image`: Путь к изображению (обязательный)
- `--detector`: Тип детектора (`sift`, `orb`, `akaze`)
- `--mode`: Режим визуализации:
    - `single`: визуализация одного детектора
    - `compare`: сравнение всех трех детекторов
    - `matches`: совпадения между двумя изображениями
- `--image2`: Второе изображение (для режима `matches`)
- `--max_keypoints`: Максимальное количество ключевых точек
- `--max_matches`: Максимальное количество совпадений (для `matches`)
- `--output_dir`: Директория для сохранения (по умолчанию `visualizations`)
- `--no_show`: Не показывать окно с результатом

#### Что показывает визуализация:

- **Зеленые круги**: ключевые точки
- **Размер кругов**: сила отклика детектора (чем больше, тем значимее точка)
- **Направление внутри круга**: ориентация ключевой точки
- **Текст**: название детектора и количество найденных точек
- **Линии** (в режиме matches): связи между совпадающими точками на двух изображениях

Все результаты автоматически сохраняются в директорию `visualizations/`.

---

## Требования к данным

- Директория `--data_dir` должна содержать `ExtDataset` и `NNSUDataset` с подпапками классов:
    - `01_NizhnyNovgorodKremlin` → класс `kremlin`
    - `04_ArkhangelskCathedral` → класс `cathedral`
    - `08_PalaceOfLabor` → класс `palace`
- Файл разбиения (`train.txt`) — список относительных путей к тренировочным изображениям
- Поддерживаемые форматы: JPG, JPEG, PNG, BMP
- Если добавляются дополнительные фото, обновите `train.txt` и создайте `references.csv` для источников

---

## Используемые библиотеки

- **OpenCV (cv2)**: Детекторы/дескрипторы (SIFT, ORB, AKAZE), чтение и обработка изображений, визуализация
- **NumPy**: Операции с массивами, гистограммы, нормализация
- **Scikit-learn**:
    - Кластеризация: `MiniBatchKMeans`
    - Классификация: `SVC` (Support Vector Classifier)
    - Метрики: `accuracy_score`, `classification_report`, `confusion_matrix`
- **Matplotlib**: Отображение результатов визуализации
- **Pickle**: Сериализация и сохранение моделей
- **JSON**: Сохранение результатов оценки
- **OS, Argparse**: Работа с файловой системой и парсинг аргументов
